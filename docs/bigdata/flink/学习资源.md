# 学习资源

[toc]

## 书籍推荐

| 书籍名称                         | 作者                              | 介绍                                                         |
| -------------------------------- | --------------------------------- | ------------------------------------------------------------ |
| 《**基于Apache Flink的流处理**》 | Fabian，Hueske，Vasiliki，Kalavri | 墙裂推荐                                                     |
| 《大数据技术之Flink》            | 尚硅谷                            | [在线阅读](https://drive.google.com/file/d/1Hcmz4QwXPcdT7BAs3Tu3SCY6rtlEKF4P/view?usp=sharing) |



## 学习网站

- Flink视频系列  [GitHub - flink-china/flink-training-course: Flink 中文视频课程（持续更新...）](https://github.com/flink-china/flink-training-course/)
- 官方网站 [Apache Flink: Stateful Computations over Data Streams](https://flink.apache.org/)

## 推荐博客

- Flink漫谈系列 [Apache Flink 漫谈-博客专辑-云栖社区-阿里云 ](https://yq.aliyun.com/album/206)

- Apache Flink进阶

   - [Apache Flink 进阶（六）：Flink 作业执行深度解析-InfoQ](https://www.infoq.cn/article/wG3ALlSsqPQxDP6CZ0k5)
      - ![image](https://static.lovedata.net/20-08-14-30711fc46567be10f60beeb165af6e50.png-wm)

- [Flink 从 0 到 1 学习 —— Apache Flink 介绍 | zhisheng的博客](http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/  )

- [精通Apache Flink必读系列文章_大数据_ffjl1985的专栏-CSDN博客](https://blog.csdn.net/ffjl1985/article/details/81775019)

- [ Flink 原理与实现：内存管理 | Jark's Blog ](http://wuchong.me/blog/2016/04/29/flink-internals-memory-manage/)

- [基于Canal与Flink实现数据实时增量同步(二) | Jmx's Blog](https://jiamaoxiang.top/2020/03/24/%E5%9F%BA%E4%BA%8ECanal%E4%B8%8EFlink%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5-%E4%BA%8C/)

   - Binlog to StreamingFileSink
   - Hive 表还原，使用full outer join
   - COALESCE 

- 项目实例

  - [[Scala\] Flink项目实例系列（零）](https://www.jianshu.com/p/3f29b83c2fc7)
     [[Scala\] Flink项目实时热门商品统计（一）](https://www.jianshu.com/p/b39019e1d044)
     [[Scala\] Flink项目实时流量统计（二）](https://www.jianshu.com/p/da2369c76609)
     [[Scala\] Flink项目恶意登录监控（三）](https://www.jianshu.com/p/455de9cac40a)
     [[Scala\] Flink项目订单支付失效监控（四）](https://www.jianshu.com/p/0da1b3e09d28)
     [[Scala\] Flink项目订单支付实时对账（五）](https://www.jianshu.com/p/234e067ba0db)
     [[Scala\] Flink项目小彩蛋（六）](https://www.jianshu.com/p/a511705e91ef)
  
- [Flink State 最佳实践 -](https://ververica.cn/developers/flink-state-best-practices/)

   - 四个维度来区分两种不同的 state：operator state 以及 keyed state。

      1. **是否存在当前处理的 key**（current key）：operator state 是没有当前 key 的概念，而 keyed state 的数值总是与一个 current key 对应。
      2. **存储对象是否 on heap:** 目前 operator state backend 仅有一种 on-heap 的实现；而 keyed state backend 有 on-heap 和 off-heap（RocksDB）的多种实现。
      3. **是否需要手动声明快照**（snapshot）**和恢复** (restore) **方法**：operator state 需要手动实现 snapshot 和 restore 方法；而 keyed state 则由 backend 自行实现，对用户透明。
      4. **数据大小**：一般而言，我们认为 operator state 的数据规模是比较小的；认为 keyed state 规模是相对比较大的。需要注意的是，这是一个经验判断，不是一个绝对的判断区分标准。

   - ![image](https://static.lovedata.net/20-08-12-3cf2b0941431e750bed467d0be92cdf5.png-wm)

   - 在生产中，我们会在 FsStateBackend 和 RocksDBStateBackend 间选择：

     - **FsStateBackend**：性能更好；日常存储是在堆内存中，面临着 OOM 的风险，不支持增量 checkpoint。
     - **RocksDBStateBackend**：无需担心 OOM 风险，是大部分时候的选择。

   - RocksDB

     - 在 RocksDB 中，每个 state 独享一个 Column Family，而每个 Column family 使用各自独享的 write buffer 和 block cache，上图中的 window state 和 value state实际上分属不同的 column family。

     - ![image](https://static.lovedata.net/20-08-12-f05823758c252aec44dd11d1da0a768a.png-wm)

     - 配置

       - | state.backend.rocksdb.thread.num        | 后台 flush 和 compaction 的线程数. 默认值 ‘1‘. 建议调大      |
         | --------------------------------------- | ------------------------------------------------------------ |
         | state.backend.rocksdb.writebuffer.count | 每个 column family 的 write buffer 数目，默认值 ‘2‘. 如果有需要可以适当调大 |
         | state.backend.rocksdb.writebuffer.size  | 每个 write buffer 的 size，默认值‘64MB‘. 对于写频繁的场景，建议调大 |
         | state.backend.rocksdb.block.cache-size  | 每个 column family 的 block cache大小，默认值‘8MB’，如果存在重复读的场景，建议调大 |

     - 实践

       - #### Operator state 使用建议

         - 慎重使用长 list  job master 就会因为收到 task 发来的“巨大”的 offset 数组，而内存不断增长直到超用无法正常响应
         -  正确使用 UnionListState。
           - union list state 目前被广泛使用在 kafka connector 中，不过可能用户日常开发中较少遇到，**<u>他的语义是从检查点恢复之后每个并发 task 内拿到的是原先所有operator 上的 state</u>**，如下图所示：
           - ![image](https://static.lovedata.net/20-08-12-85082be4bcaa670c407006efbf51102a.png-wm)

       - #### Keyed state 使用建议

         - 如何正确清空当前的 state
           - state.clear() 只能清理当前key的state，如果想要清空整个 state，需要借助于 applyToAllKeys 方法
           - ![image](https://static.lovedata.net/20-08-12-cc9d7e078ba46da002aba1cf665b0acf.png-wm)
           - state 有过期需求，借助于 state TTL  

       - #### 一些使用 checkpoint 的使用建议

         - ##### Checkpoint 间隔不要太短

         - ##### 合理设置超时时间





## 源码解析

- miaowenting
  - [Flink源码剖析-flink-metrics | Matty's Blog](https://miaowenting.site/2020/04/05/Flink%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-Flink-Metrics/)
- [Flink 系列文章目录 - 简书](https://www.jianshu.com/p/59070e64eba1?utm_campaign=haruki&utm_content=note&utm_medium=reader_share&utm_source=weixin_timeline&from=timeline)
- [Flink原理与实现：详解Flink中的状态管理-阿里云开发者社区](https://developer.aliyun.com/article/225623)
  - Keyed State。，就是基于KeyedStream上的状态。这个状态是跟特定的key绑定的，对KeyedStream流上的每一个key，可能都对应一个state。
  - Operator State 并发实例绑定，每个operater一个state
  - 原始状态和托管状态
    - 托管状态 是flink框架管理的，如 valuestate。liststate  mapstate
      - ![image](https://static.lovedata.net/20-08-03-52f3a6ef6507dcd13f9e94019b863a0c.png-wm)
    - raw state。原始状态，有用户自行管理状态数据结构，框架在做checkpoint的时候，使用byte[] 来读取状态内容，对其**内部数据结构一无所知** 通常使用flink的托管状态
- [Apache Flink 进阶（三）：Checkpoint 原理解析与应用实践-阿里云开发者社区](https://developer.aliyun.com/article/719242)



## 大厂实践

### OPPO

- [进击的实时数仓：Flink在OPPO实时计算平台的研发与应用实践-InfoQ](https://www.infoq.cn/article/VmLAOsm*939Rdgb9mfrH)

### 有赞

- [Flink 在有赞实时计算的实践](https://tech.youzan.com/flink-practice/)

### 趣头条

- [趣头条基于Flink+ClickHouse的实时数据分析平台](https://mp.weixin.qq.com/s?src=11&timestamp=1593500391&ver=2431&signature=MeB1KSj8wJTjoVvLUPgTMiGmKqIsD*V-eBpN34iKir3cAFAaOYiW*pweqAZ*4ZXsxqpMr*tYY7dJZSaATYRUF8BLHy*tOVDD9NQmJq3M7IZr0I53*dVvpSyAaZ*WQUKq&new=1)
  - Flink to hive
    - ![image](https://static.lovedata.net/20-06-30-299d3b7d12ea6155dcb1ad1e26f434b3.png-wm)
    - **原理**
      - StreamingFileSink
      - ![image](https://static.lovedata.net/20-06-30-fbe1904d55623b468eabaf1b0141232e.png-wm)
      - 功能
        - forBulkFormat支持avro、parquet格式
        - 按照数据时间粪桶  withBucketAssigner
        -  Exactly-Once
  - Flink to Click House
    - ![image](https://static.lovedata.net/20-06-30-a5ee614eb959a55a331a6bd256bb24b9.png-wm)
    - ![image](https://static.lovedata.net/20-06-30-727257999ebfe59afc39bf08b6826643.png-wm)

### 贝壳

​	1. [贝壳找房基于 Flink 的实时平台建设 - 云+社区 - 腾讯云](https://cloud.tencent.com/developer/article/1596741)

