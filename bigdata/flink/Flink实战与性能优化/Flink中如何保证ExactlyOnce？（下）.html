<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Flink中如何保证ExactlyOnce？（下） | 编程手册</title>
    <meta name="generator" content="VuePress 1.7.1">
    <link rel="icon" href="/logo.png">
    <link rel="manifest" href="/manifest.json">
    <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#3eaf7c">
    <meta name="description" content="苍穹浩渺,取之须臾">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
    <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/assets/css/0.styles.225a8ff9.css" as="style"><link rel="preload" href="/assets/js/app.0f56a723.js" as="script"><link rel="preload" href="/assets/js/4.a8ef5668.js" as="script"><link rel="preload" href="/assets/js/46.691097de.js" as="script"><link rel="preload" href="/assets/js/11.0473ae06.js" as="script"><link rel="prefetch" href="/assets/js/10.06cc4fbb.js"><link rel="prefetch" href="/assets/js/100.79e96d05.js"><link rel="prefetch" href="/assets/js/101.bcac0b9f.js"><link rel="prefetch" href="/assets/js/102.c5d92a95.js"><link rel="prefetch" href="/assets/js/103.697856ab.js"><link rel="prefetch" href="/assets/js/104.8f2db4d2.js"><link rel="prefetch" href="/assets/js/105.d4f2bb07.js"><link rel="prefetch" href="/assets/js/106.1a533c3f.js"><link rel="prefetch" href="/assets/js/107.b2845ea0.js"><link rel="prefetch" href="/assets/js/108.226e46ed.js"><link rel="prefetch" href="/assets/js/109.0de9c16c.js"><link rel="prefetch" href="/assets/js/110.4657c34b.js"><link rel="prefetch" href="/assets/js/111.3409d3a7.js"><link rel="prefetch" href="/assets/js/112.a46b486c.js"><link rel="prefetch" href="/assets/js/113.ba001fa9.js"><link rel="prefetch" href="/assets/js/114.ad1e6ba1.js"><link rel="prefetch" href="/assets/js/115.a0ac732f.js"><link rel="prefetch" href="/assets/js/116.4ee2a7b2.js"><link rel="prefetch" href="/assets/js/117.a76fd29a.js"><link rel="prefetch" href="/assets/js/118.83c5badf.js"><link rel="prefetch" href="/assets/js/119.09fec567.js"><link rel="prefetch" href="/assets/js/12.286e979d.js"><link rel="prefetch" href="/assets/js/120.42120fe1.js"><link rel="prefetch" href="/assets/js/121.9d79a9dd.js"><link rel="prefetch" href="/assets/js/122.f71a459c.js"><link rel="prefetch" href="/assets/js/123.b75308dc.js"><link rel="prefetch" href="/assets/js/124.e4d4643b.js"><link rel="prefetch" href="/assets/js/125.73fc990d.js"><link rel="prefetch" href="/assets/js/126.3b0eccd0.js"><link rel="prefetch" href="/assets/js/127.3eb3ab27.js"><link rel="prefetch" href="/assets/js/128.64ba68bb.js"><link rel="prefetch" href="/assets/js/129.82cfac7a.js"><link rel="prefetch" href="/assets/js/13.7207d991.js"><link rel="prefetch" href="/assets/js/130.42811f32.js"><link rel="prefetch" href="/assets/js/131.6f498e16.js"><link rel="prefetch" href="/assets/js/132.f0cc9ad2.js"><link rel="prefetch" href="/assets/js/133.325e755a.js"><link rel="prefetch" href="/assets/js/134.076a808c.js"><link rel="prefetch" href="/assets/js/135.fad7be83.js"><link rel="prefetch" href="/assets/js/136.042fc555.js"><link rel="prefetch" href="/assets/js/137.b67b55bc.js"><link rel="prefetch" href="/assets/js/138.6476c99f.js"><link rel="prefetch" href="/assets/js/139.ad07500f.js"><link rel="prefetch" href="/assets/js/14.a1cb7c1b.js"><link rel="prefetch" href="/assets/js/140.3edd2237.js"><link rel="prefetch" href="/assets/js/141.5181db27.js"><link rel="prefetch" href="/assets/js/142.67b4c4a2.js"><link rel="prefetch" href="/assets/js/143.9d249a3f.js"><link rel="prefetch" href="/assets/js/144.e6db5540.js"><link rel="prefetch" href="/assets/js/145.5b4305a7.js"><link rel="prefetch" href="/assets/js/146.bc674178.js"><link rel="prefetch" href="/assets/js/147.964ff3df.js"><link rel="prefetch" href="/assets/js/148.570b6864.js"><link rel="prefetch" href="/assets/js/149.4b9796c2.js"><link rel="prefetch" href="/assets/js/15.3cafda64.js"><link rel="prefetch" href="/assets/js/150.c677bf4b.js"><link rel="prefetch" href="/assets/js/151.b8977c93.js"><link rel="prefetch" href="/assets/js/152.535e2db4.js"><link rel="prefetch" href="/assets/js/153.754fc05e.js"><link rel="prefetch" href="/assets/js/154.5a5928b6.js"><link rel="prefetch" href="/assets/js/155.19893ca5.js"><link rel="prefetch" href="/assets/js/156.da1f2665.js"><link rel="prefetch" href="/assets/js/157.cb7b551f.js"><link rel="prefetch" href="/assets/js/158.f5d94a11.js"><link rel="prefetch" href="/assets/js/159.0b2b78d9.js"><link rel="prefetch" href="/assets/js/16.54ab9242.js"><link rel="prefetch" href="/assets/js/160.c2548b6c.js"><link rel="prefetch" href="/assets/js/161.8f694ed1.js"><link rel="prefetch" href="/assets/js/162.1adc1aa4.js"><link rel="prefetch" href="/assets/js/163.5688827c.js"><link rel="prefetch" href="/assets/js/164.8442474f.js"><link rel="prefetch" href="/assets/js/165.d0e21e5c.js"><link rel="prefetch" href="/assets/js/166.2e90ae99.js"><link rel="prefetch" href="/assets/js/167.374185de.js"><link rel="prefetch" href="/assets/js/168.2426769f.js"><link rel="prefetch" href="/assets/js/169.829516d9.js"><link rel="prefetch" href="/assets/js/17.9cad59f9.js"><link rel="prefetch" href="/assets/js/170.db0c4609.js"><link rel="prefetch" href="/assets/js/171.7bdcc41b.js"><link rel="prefetch" href="/assets/js/172.7f7ab109.js"><link rel="prefetch" href="/assets/js/173.c1d51df9.js"><link rel="prefetch" href="/assets/js/174.afa4c5f6.js"><link rel="prefetch" href="/assets/js/175.b46d9dd8.js"><link rel="prefetch" href="/assets/js/176.c38ba756.js"><link rel="prefetch" href="/assets/js/177.ba85b912.js"><link rel="prefetch" href="/assets/js/178.af1a44e8.js"><link rel="prefetch" href="/assets/js/179.e097e164.js"><link rel="prefetch" href="/assets/js/18.3776b09c.js"><link rel="prefetch" href="/assets/js/180.d9d5d80c.js"><link rel="prefetch" href="/assets/js/181.79401f8c.js"><link rel="prefetch" href="/assets/js/182.343db47f.js"><link rel="prefetch" href="/assets/js/183.005841bb.js"><link rel="prefetch" href="/assets/js/19.d0ac1e7f.js"><link rel="prefetch" href="/assets/js/20.e0100fb2.js"><link rel="prefetch" href="/assets/js/21.f59cd52c.js"><link rel="prefetch" href="/assets/js/22.3ecf54da.js"><link rel="prefetch" href="/assets/js/23.2508850b.js"><link rel="prefetch" href="/assets/js/24.0ac10322.js"><link rel="prefetch" href="/assets/js/25.7c3ee156.js"><link rel="prefetch" href="/assets/js/26.7021c42c.js"><link rel="prefetch" href="/assets/js/27.d716476b.js"><link rel="prefetch" href="/assets/js/28.58ebf808.js"><link rel="prefetch" href="/assets/js/29.88c37f6c.js"><link rel="prefetch" href="/assets/js/30.87bc4a91.js"><link rel="prefetch" href="/assets/js/31.a69c2a35.js"><link rel="prefetch" href="/assets/js/32.89f74912.js"><link rel="prefetch" href="/assets/js/33.df886872.js"><link rel="prefetch" href="/assets/js/34.835d0785.js"><link rel="prefetch" href="/assets/js/35.5e38ab06.js"><link rel="prefetch" href="/assets/js/36.5b639051.js"><link rel="prefetch" href="/assets/js/37.bb32ead0.js"><link rel="prefetch" href="/assets/js/38.c2541da0.js"><link rel="prefetch" href="/assets/js/39.3c8f0f06.js"><link rel="prefetch" href="/assets/js/40.4cc077aa.js"><link rel="prefetch" href="/assets/js/41.cbcd81a7.js"><link rel="prefetch" href="/assets/js/42.6d002f78.js"><link rel="prefetch" href="/assets/js/43.3f67c882.js"><link rel="prefetch" href="/assets/js/44.58ce7a4d.js"><link rel="prefetch" href="/assets/js/45.bfb9d6e0.js"><link rel="prefetch" href="/assets/js/47.e6b5c9b5.js"><link rel="prefetch" href="/assets/js/48.38159f5c.js"><link rel="prefetch" href="/assets/js/49.e03ce66a.js"><link rel="prefetch" href="/assets/js/5.340b4b76.js"><link rel="prefetch" href="/assets/js/50.7df345cb.js"><link rel="prefetch" href="/assets/js/51.b3eed5d5.js"><link rel="prefetch" href="/assets/js/52.bb282842.js"><link rel="prefetch" href="/assets/js/53.6b21ec8f.js"><link rel="prefetch" href="/assets/js/54.bab98944.js"><link rel="prefetch" href="/assets/js/55.59437904.js"><link rel="prefetch" href="/assets/js/56.18b88131.js"><link rel="prefetch" href="/assets/js/57.b0cbba56.js"><link rel="prefetch" href="/assets/js/58.d9379002.js"><link rel="prefetch" href="/assets/js/59.e8663882.js"><link rel="prefetch" href="/assets/js/6.c48e1ddb.js"><link rel="prefetch" href="/assets/js/60.0a00b724.js"><link rel="prefetch" href="/assets/js/61.cd09980d.js"><link rel="prefetch" href="/assets/js/62.b092ff62.js"><link rel="prefetch" href="/assets/js/63.86482c79.js"><link rel="prefetch" href="/assets/js/64.3c1ee4d2.js"><link rel="prefetch" href="/assets/js/65.0621decf.js"><link rel="prefetch" href="/assets/js/66.cf7a6241.js"><link rel="prefetch" href="/assets/js/67.99e103bc.js"><link rel="prefetch" href="/assets/js/68.b3589f28.js"><link rel="prefetch" href="/assets/js/69.f0932a12.js"><link rel="prefetch" href="/assets/js/7.0f410b85.js"><link rel="prefetch" href="/assets/js/70.0a941773.js"><link rel="prefetch" href="/assets/js/71.3a6c6141.js"><link rel="prefetch" href="/assets/js/72.2299ff58.js"><link rel="prefetch" href="/assets/js/73.544fe8c6.js"><link rel="prefetch" href="/assets/js/74.98219c05.js"><link rel="prefetch" href="/assets/js/75.244a9d80.js"><link rel="prefetch" href="/assets/js/76.cefd9fe2.js"><link rel="prefetch" href="/assets/js/77.59793840.js"><link rel="prefetch" href="/assets/js/78.a7d9a079.js"><link rel="prefetch" href="/assets/js/79.f9ec013d.js"><link rel="prefetch" href="/assets/js/8.269955a4.js"><link rel="prefetch" href="/assets/js/80.b0f2cbe5.js"><link rel="prefetch" href="/assets/js/81.3d245e9a.js"><link rel="prefetch" href="/assets/js/82.061b170d.js"><link rel="prefetch" href="/assets/js/83.d2c42148.js"><link rel="prefetch" href="/assets/js/84.f6f487a4.js"><link rel="prefetch" href="/assets/js/85.c5305650.js"><link rel="prefetch" href="/assets/js/86.0c30a2ef.js"><link rel="prefetch" href="/assets/js/87.d9a99f2e.js"><link rel="prefetch" href="/assets/js/88.03792030.js"><link rel="prefetch" href="/assets/js/89.95684850.js"><link rel="prefetch" href="/assets/js/9.5c3462fb.js"><link rel="prefetch" href="/assets/js/90.185b012e.js"><link rel="prefetch" href="/assets/js/91.d19f0020.js"><link rel="prefetch" href="/assets/js/92.9e7855de.js"><link rel="prefetch" href="/assets/js/93.1ee902df.js"><link rel="prefetch" href="/assets/js/94.4bfab4ad.js"><link rel="prefetch" href="/assets/js/95.5f0b1d15.js"><link rel="prefetch" href="/assets/js/96.bd50a446.js"><link rel="prefetch" href="/assets/js/97.749fd671.js"><link rel="prefetch" href="/assets/js/98.bc09c746.js"><link rel="prefetch" href="/assets/js/99.40f98e75.js"><link rel="prefetch" href="/assets/js/vendors~flowchart.98d8c7d3.js"><link rel="prefetch" href="/assets/js/vendors~notification.5515ddcd.js">
    <link rel="stylesheet" href="/assets/css/0.styles.225a8ff9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">编程手册</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">
  算法 
</a></div><div class="nav-item"><a href="/architecture/" class="nav-link">
  架构 
</a></div><div class="nav-item"><a href="/computer/" class="nav-link">
  计算机 
</a></div><div class="nav-item"><a href="/database/" class="nav-link">
  数据库 
</a></div><div class="nav-item"><a href="/fe/" class="nav-link">
  前端
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维 " class="dropdown-title"><span class="title">运维 </span> <span class="arrow down"></span></button> <button type="button" aria-label="运维 " class="mobile-dropdown-title"><span class="title">运维 </span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ops/" class="nav-link">
  基础
</a></li><li class="dropdown-item"><h4>
          分类
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ops/java.html" class="nav-link">
  Java
</a></li><li class="dropdown-subitem"><a href="/ops/bigdata.html" class="nav-link">
  大数据
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程" class="dropdown-title"><span class="title">编程</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程" class="mobile-dropdown-title"><span class="title">编程</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          语言
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/programming/python.html" class="nav-link">
  Python
</a></li><li class="dropdown-subitem"><a href="/programming/scala.html" class="nav-link">
  Scala
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="资源" class="dropdown-title"><span class="title">资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="资源" class="mobile-dropdown-title"><span class="title">资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          我的书单
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/tech.html" class="nav-link">
  技术类
</a></li><li class="dropdown-subitem"><a href="/book/growth.html" class="nav-link">
  成长类
</a></li></ul></li><li class="dropdown-item"><h4>
          网课
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/geek.html" class="nav-link">
  专栏
</a></li><li class="dropdown-subitem"><a href="/book/video.html" class="nav-link">
  视频
</a></li></ul></li><li class="dropdown-item"><h4>
          面经
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/interview/tech.html" class="nav-link">
  大厂面经
</a></li><li class="dropdown-subitem"><a href="/interview/sword-to-offer.html" class="nav-link">
  剑指Offer
</a></li><li class="dropdown-subitem"><a href="/interview/fe.html" class="nav-link">
  前端面经
</a></li><li class="dropdown-subitem"><a href="/interview/interview_guide.html" class="nav-link">
  面试导航
</a></li></ul></li><li class="dropdown-item"><h4>
          其他
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/study.html" class="nav-link">
  学习笔记
</a></li></ul></li></ul></div></div> <a href="https://github.com/pengshuangbao/databook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">
  算法 
</a></div><div class="nav-item"><a href="/architecture/" class="nav-link">
  架构 
</a></div><div class="nav-item"><a href="/computer/" class="nav-link">
  计算机 
</a></div><div class="nav-item"><a href="/database/" class="nav-link">
  数据库 
</a></div><div class="nav-item"><a href="/fe/" class="nav-link">
  前端
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维 " class="dropdown-title"><span class="title">运维 </span> <span class="arrow down"></span></button> <button type="button" aria-label="运维 " class="mobile-dropdown-title"><span class="title">运维 </span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ops/" class="nav-link">
  基础
</a></li><li class="dropdown-item"><h4>
          分类
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ops/java.html" class="nav-link">
  Java
</a></li><li class="dropdown-subitem"><a href="/ops/bigdata.html" class="nav-link">
  大数据
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程" class="dropdown-title"><span class="title">编程</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程" class="mobile-dropdown-title"><span class="title">编程</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          语言
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/programming/python.html" class="nav-link">
  Python
</a></li><li class="dropdown-subitem"><a href="/programming/scala.html" class="nav-link">
  Scala
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="资源" class="dropdown-title"><span class="title">资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="资源" class="mobile-dropdown-title"><span class="title">资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          我的书单
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/tech.html" class="nav-link">
  技术类
</a></li><li class="dropdown-subitem"><a href="/book/growth.html" class="nav-link">
  成长类
</a></li></ul></li><li class="dropdown-item"><h4>
          网课
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/geek.html" class="nav-link">
  专栏
</a></li><li class="dropdown-subitem"><a href="/book/video.html" class="nav-link">
  视频
</a></li></ul></li><li class="dropdown-item"><h4>
          面经
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/interview/tech.html" class="nav-link">
  大厂面经
</a></li><li class="dropdown-subitem"><a href="/interview/sword-to-offer.html" class="nav-link">
  剑指Offer
</a></li><li class="dropdown-subitem"><a href="/interview/fe.html" class="nav-link">
  前端面经
</a></li><li class="dropdown-subitem"><a href="/interview/interview_guide.html" class="nav-link">
  面试导航
</a></li></ul></li><li class="dropdown-item"><h4>
          其他
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/study.html" class="nav-link">
  学习笔记
</a></li></ul></li></ul></div></div> <a href="https://github.com/pengshuangbao/databook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/bigdata/" aria-current="page" class="sidebar-link">大数据</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Hadoop</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spark</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Flink</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/flink/" aria-current="page" class="sidebar-link">Flink</a></li><li><a href="/bigdata/flink/通关手册.html" class="sidebar-link">通关手册</a></li><li><a href="/bigdata/flink/学习资源.html" class="sidebar-link">学习资源</a></li><li><a href="/bigdata/flink/开源动态.html" class="sidebar-link">开源动态</a></li><li><a href="/bigdata/flink/Flink状态原理.html" class="sidebar-link">状态原理</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Flink实战与性能优化</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/flink/Flink实战与性能优化/公司到底需不需要引入实时计算引擎？.html" class="sidebar-link">公司到底需不需要引入实时计算引擎？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/彻底了解大数据实时计算框架Flink.html" class="sidebar-link">彻底了解大数据实时计算框架Flink</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/大数据框架Flink、Blink、SparkStreaming、StructuredStreaming和Storm之间的区别.html" class="sidebar-link">大数据框架Flink、Blink、SparkStreaming、StructuredStreaming和Storm之间的区别</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink环境准备.html" class="sidebar-link">Flink环境准备</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink环境搭建.html" class="sidebar-link">Flink环境搭建</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWordCount应用程序.html" class="sidebar-link">FlinkWordCount应用程序</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink实时处理Socket数据.html" class="sidebar-link">Flink实时处理Socket数据</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink多种时间语义对比.html" class="sidebar-link">Flink多种时间语义对比</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWindow基础概念与实现原理.html" class="sidebar-link">FlinkWindow基础概念与实现原理</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/数据转换必须熟悉的算子（Operator）.html" class="sidebar-link">数据转换必须熟悉的算子（Operator）</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用DataStreamAPI来处理数据？.html" class="sidebar-link">如何使用DataStreamAPI来处理数据？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWaterMark详解及结合WaterMark处理延迟数据.html" class="sidebar-link">FlinkWaterMark详解及结合WaterMark处理延迟数据</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink常用的Source和SinkConnectors介绍.html" class="sidebar-link">Flink常用的Source和SinkConnectors介绍</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkConnectorKafka使用和剖析.html" class="sidebar-link">FlinkConnectorKafka使用和剖析</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何自定义FlinkConnectors（Source和Sink）？.html" class="sidebar-link">如何自定义FlinkConnectors（Source和Sink）？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——ElasticSearch？.html" class="sidebar-link">如何使用FlinkConnectors——ElasticSearch？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——HBase？.html" class="sidebar-link">如何使用FlinkConnectors——HBase？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——Redis？.html" class="sidebar-link">如何使用FlinkConnectors——Redis？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用SideOutput来分流.html" class="sidebar-link">如何使用SideOutput来分流</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkState深度讲解.html" class="sidebar-link">FlinkState深度讲解</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何选择Flink状态后端存储.html" class="sidebar-link">如何选择Flink状态后端存储</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCheckpoint和Savepoint区别及其如何配置使用？.html" class="sidebar-link">FlinkCheckpoint和Savepoint区别及其如何配置使用？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkTable&amp;SQL概念与通用API.html" class="sidebar-link">FlinkTable&amp;SQL概念与通用API</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkTableAPI&amp;SQL功能.html" class="sidebar-link">FlinkTableAPI&amp;SQL功能</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCEP介绍及其使用场景.html" class="sidebar-link">FlinkCEP介绍及其使用场景</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCEP如何处理复杂事件？.html" class="sidebar-link">FlinkCEP如何处理复杂事件？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——StateProcessorAPI.html" class="sidebar-link">Flink扩展库——StateProcessorAPI</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——MachineLearning.html" class="sidebar-link">Flink扩展库——MachineLearning</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——Gelly.html" class="sidebar-link">Flink扩展库——Gelly</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink配置详解及如何配置高可用？.html" class="sidebar-link">Flink配置详解及如何配置高可用？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkJob如何在Standalone、YARN、Mesos、K8S上部署运行？.html" class="sidebar-link">FlinkJob如何在Standalone、YARN、Mesos、K8S上部署运行？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何实时监控Flink和你的Job？.html" class="sidebar-link">如何实时监控Flink和你的Job？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何搭建一套完整的Flink监控系统.html" class="sidebar-link">如何搭建一套完整的Flink监控系统</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何处理FlinkJobBackPressure（反压）问题？.html" class="sidebar-link">如何处理FlinkJobBackPressure（反压）问题？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何查看FlinkJob执行计划？.html" class="sidebar-link">如何查看FlinkJob执行计划？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkParallelism和Slot深度理解.html" class="sidebar-link">FlinkParallelism和Slot深度理解</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何合理的设置FlinkJob并行度？.html" class="sidebar-link">如何合理的设置FlinkJob并行度？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（上）.html" class="sidebar-link">Flink中如何保证ExactlyOnce？（上）</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（下）.html" class="active sidebar-link">Flink中如何保证ExactlyOnce？（下）</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何处理Flink中数据倾斜问题？.html" class="sidebar-link">如何处理Flink中数据倾斜问题？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何设置FlinkJobRestartStrategy（重启策略）？.html" class="sidebar-link">如何设置FlinkJobRestartStrategy（重启策略）？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkParameterTool读取配置？.html" class="sidebar-link">如何使用FlinkParameterTool读取配置？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何统计网站各页面一天内的PV和UV？.html" class="sidebar-link">如何统计网站各页面一天内的PV和UV？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkProcessFunction处理宕机告警.html" class="sidebar-link">如何使用FlinkProcessFunction处理宕机告警</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何利用AsyncIO读取告警规则？.html" class="sidebar-link">如何利用AsyncIO读取告警规则？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何利用广播变量动态更新告警规则？.html" class="sidebar-link">如何利用广播变量动态更新告警规则？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何实时将应用Error日志告警？.html" class="sidebar-link">如何实时将应用Error日志告警？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/基于Flink的海量日志实时处理系统的实践.html" class="sidebar-link">基于Flink的海量日志实时处理系统的实践</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/基于Flink的百亿数据去重实践.html" class="sidebar-link">基于Flink的百亿数据去重实践</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kylin</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kafka</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Hbase</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>ClickHouse</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Impala</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kudu</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Redis</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>hive</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/bigdata/zookeeper.html" class="sidebar-link">Zookeeper</a></li><li><a href="/bigdata/solution.html" class="sidebar-link">解决方案</a></li><li><a href="/bigdata/design.html" class="sidebar-link">编程设计</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="flink中如何保证exactlyonce-下"><a href="#flink中如何保证exactlyonce-下" class="header-anchor">#</a> Flink中如何保证ExactlyOnce？（下）</h1> <p></p><div class="table-of-contents"><ul><li><a href="#分析-flinkkafkaconsumer-的设计思想">分析 FlinkKafkaConsumer 的设计思想</a><ul><li><a href="#kafka-offset-存储及如何实现-consumer-实例消费-partition-的负载均衡">Kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡</a></li><li><a href="#source-端并行度改变了-如何来恢复-offset">Source 端并行度改变了，如何来恢复 offset</a></li><li><a href="#如何实现自动发现当前消费-topic-下新增的-partition">如何实现自动发现当前消费 topic 下新增的 partition</a></li></ul></li><li><a href="#小结与反思">小结与反思</a></li></ul></div><p></p> <h3 id="分析-flinkkafkaconsumer-的设计思想"><a href="#分析-flinkkafkaconsumer-的设计思想" class="header-anchor">#</a> 分析 FlinkKafkaConsumer 的设计思想</h3> <p>FlinkKafkaConsumer 做为 Source，从 Kafka 读取数据到 Flink 中，首先想一下设计
FlinkKafkaConsumer，需要考虑哪些？</p> <ul><li>Flink 中 kafka 的 offset 保存在哪里，具体如何保存呢？任务重启恢复时，如何读取之前消费的 offset？</li> <li>如果 Source 端并行度改变了，如何来恢复 offset？</li> <li>如何保证每个 FlinkKafkaConsumer 实例消费的 partition 负载均衡？如何保证不出现有的实例消费 5 个 kafka partition，有的实例仅消费 1 个 kafka partition？</li> <li>当前消费的 topic 如果动态增加了 partition，Flink 如何实现自动发现并消费？</li></ul> <p>带着这些问题来看一看 FlinkKafkaConsumer 是怎么解决上述问题的。</p> <h4 id="kafka-offset-存储及如何实现-consumer-实例消费-partition-的负载均衡"><a href="#kafka-offset-存储及如何实现-consumer-实例消费-partition-的负载均衡" class="header-anchor">#</a> Kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡</h4> <p>Flink 将任务恢复需要的信息都保存在状态中，当然 Kafka 的 offset 信息也保存在 Flink
的状态中，当任务从状态中恢复时会从状态中读取相应的 offset，并从 offset 位置开始消费。</p> <p>在 Flink 中有两个基本的 State：<strong>Keyed State</strong> 和 <strong>Operator State</strong>。</p> <ul><li>Keyed State 只能用于 KeyedStream 的 function 和 Operator 中，一个 Key 对应一个 State；</li> <li>而 Operator State 可以用于所有类型的 function 和 Operator 中，一个 Operator 实例对应一个 State，假如一个算子并行度是 5 且使用 Operator State，那么这个算子的每个并行度都对应一个 State，总共 5 个 State。</li></ul> <p>FlinkKafkaConsumer 做为 Source 只能使用 Operator State，<strong>Operator State 只支持一种数据结构</strong> <strong>ListState</strong>，可以当做 List 类型的 State。所以 FlinkKafkaConsumer 中，将状态保存在 Operator State
对应的 ListState 中。具体如何保存呢？需要先了解每个 FlinkKafkaConsumer 具体怎么消费 Kafka。</p> <p>对于同一个消费者组，Kafka 要求 topic 的每个 partition 只能被一个 Consumer 实例消费，相反一个 Consumer
实例可以去消费多个 partition。当 Flink 消费 Kafka 时，出现了以下三种情况：</p> <table><thead><tr><th>情况</th> <th>现象</th></tr></thead> <tbody><tr><td>FlinkKafkaConsumer 并行度大于 topic 的 partition 数</td> <td>有些 FlinkKafkaConsumer 不会消费Kafka</td></tr> <tr><td>FlinkKafkaConsumer 并行度等于 topic 的 partition 数</td> <td>每个 FlinkKafkaConsumer 消费 1 个partition</td></tr> <tr><td>FlinkKafkaConsumer 并行度小于 topic 的 partition 数</td> <td>每个 FlinkKafkaConsumer 至少消费 1 个partition，可能会消费多个 partition</td></tr></tbody></table> <p>Flink 是如何为每个 Consumer 实例合理地分配去消费哪些 partition 呢？源码中 <strong>KafkaTopicPartitionAssigner</strong>
类的<mark> assign</mark> 方法，负责分配 partition 给 Consumer 实例。assign 方法的输入参数为 KafkaTopicPartition
和 Consumer 的并行度，KafkaTopicPartition 主要包含两个字段：String 类型的 topic 和 int 类型的
partition。assign 方法返回该 KafkaTopicPartition 应该分配给哪个 Consumer 实例去消费。假如 Consumer
的并行度为 5，表示包含了 5 个 subtask，assign 方法的返回值范围为 0~4，分别表示该 partition 分配给
subtask0-subtask4。</p> <div class="language-java extra-class"><pre class="language-java"><code>  <span class="token comment">/**
     * @param partition Kafka 中 topic 和 partition 信息
     * @param numParallelSubtasks subtask 的数量
     * @return 该 KafkaTopicPartition 分配给哪个 subtask 去消费
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">KafkaTopicPartition</span> partition<span class="token punctuation">,</span> <span class="token keyword">int</span> numParallelSubtasks<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">int</span> startIndex <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>partition<span class="token punctuation">.</span><span class="token function">getTopic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">31</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token number">0x7FFFFFFF</span><span class="token punctuation">)</span> <span class="token operator">%</span> numParallelSubtasks<span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>startIndex <span class="token operator">+</span> partition<span class="token punctuation">.</span><span class="token function">getPartition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">%</span> numParallelSubtasks<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre></div><p>assign 方法是如何给 KafkaTopicPartition 分配 Consumer 实例的呢？</p> <p>第一行代码根据 topic name 的 hashCode 运算后对 subtask 的数量求余生成一个 startIndex，第二行代码用
startIndex + partition 编号对 subtask 的数量求余，可以保证该 topic 的 0 号 partition 分配给
startIndex 对应的 subtask，后续的 partition 依次分配给后续的 subtask。</p> <p>例如，名为 &quot;test-topic&quot; 的 topic 有 11 个 partition 分别为
partition0-partition10，Consumer 有 5 个并行度分别为 subtask0-subtask4。计算后的 startIndex
为 1，表示 partition0 分配给 subtask1，partition1 分配给 subtask2 以此类推，subtask 与
partition 的对应关系如下图所示。</p> <p>assign 方法给 partition 分配 subtask 实际上是轮循的策略，首先计算一个起点 startIndex 分配给
partition0，后续的 partition 轮循地分配给 subtask，从而使得每个 subtask 消费的 partition 得以均衡。</p> <p><img src="https://static.lovedata.net/zs/2019-10-19-122937.jpg" alt="images"></p> <p>每个 subtask 只负责一部分 partition，所以在维护 partition 的 offset 信息时，每个 subtask 只需要将自己消费的
partition 的 offset 信息保存到状态中即可。</p> <p>保存的格式理论来讲应该是 kv 键值对，key 为 KafkaTopicPartition，value 为 Long 类型的 offset 值。但
Flink 的 Operator State 只支持 ListState 一种数据结构，不支持 kv 格式，可以将 KafkaTopicPartition
和 Long 封装为 Tuple2&lt;KafkaTopicPartition, Long&gt; 存储到 ListState 中。如下所示，Flink
源码中确实如此，使用 ListState&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt; 类型的 <strong>unionOffsetStates</strong>
来保存 Kafka 的 offset 信息。</p> <div class="language-java extra-class"><pre class="language-java"><code>    <span class="token comment">/** Accessor for state in the operator state backend. */</span>
    <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token class-name">ListState</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> unionOffsetStates<span class="token punctuation">;</span>
</code></pre></div><p>当 Flink 应用从 Checkpoint 恢复任务时，会从 unionOffsetStates 中读取上一次 Checkpoint 保存的 offset
信息，并从 offset 的位置开始继续消费，从而实现 Flink 任务的故障容错。例如，任务重启后，Operator State 是一个 Operator
实例对应一个 State，subtask0 依然消费 partition4 和 partition9，subtask0 从自己的 State 中可以读取到
partition4 和 partition9 消费的 offset，从 offset 位置接着往后消费即可。问题来了，<strong>若</strong> <strong>FlinkKafkaConsumer 的并行度改变后，offset 信息如何恢复呢？</strong></p> <h4 id="source-端并行度改变了-如何来恢复-offset"><a href="#source-端并行度改变了-如何来恢复-offset" class="header-anchor">#</a> Source 端并行度改变了，如何来恢复 offset</h4> <p>subtask1 当前消费了 3 个 partition，而其他 subtask 仅消费 2 个 partition，当发现 subtask1 读取
Kafka 成为瓶颈后，需要调大 Consumer 的并行度，使得每个 subtask 最多仅消费 2 个 partition。将 Consumer
实例的并行度增大到 6 以后，分配器对 partition 重新分配给 6 个 subtask，计算后的 startIndex 为 0，表示
partition0 分配给 subtask0，后续的 partition 采用轮循策略，partition 与 subtask 的对应关系如下。</p> <p><img src="https://static.lovedata.net/zs/2019-10-19-122939.jpg" alt="images"></p> <p>之前 subtask0 消费 partition 4 和 9，并行度调大以后，subtask0 被分配消费 partition 0 和 6。但是 Flink
任务从 Checkpoint 恢复后，能保证 subtask0 读取到 partition 0 和 6 的 offset 吗？这个就需要深入了解当
Flink 算子并行度改变后，Operator State 的 ListState 两种恢复策略。两种策略如下所示，在 initializeState
方法中执行相应 API 来恢复。</p> <div class="language-java extra-class"><pre class="language-java"><code>    <span class="token class-name">OperatorStateStore</span> stateStore <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getOperatorStateStore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// 通过 getListState 获取 ListState</span>
    stateStore<span class="token punctuation">.</span><span class="token function">getListState</span><span class="token punctuation">(</span><span class="token class-name">ListStateDescriptor</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">S</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// 通过 getUnionListState 获取 ListState</span>
    stateStore<span class="token punctuation">.</span><span class="token function">getUnionListState</span><span class="token punctuation">(</span><span class="token class-name">ListStateDescriptor</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">S</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>当并行度改变后，<strong>getListState</strong> 恢复策略是均匀分配，将 ListState 中保存的所有元素均匀地分配到所有并行度中，每个 subtask
获取到其中一部分状态信息。</p> <p><strong>getUnionListState</strong> 策略是将所有的状态信息合并后，每个 subtask 都获取到全量的状态信息。在 FlinkKafkaConsumer
中，假如使用 getListState 来获取 ListState，采用均匀分配状态信息的策略，Flink 可能给 subtask0 分配了partition0 和 partition1 的 offset 信息，但实际上分配器让 subtask0 去消费 partition0 和partition6，此时 subtask0 并拿不到 partition 6 的 offset 信息，不知道该从 partition 6哪个位置消费，<strong>所以均匀分配状态信息的策略并不能满足需求</strong>。</p> <p>这里应该使用 <strong>getUnionListState</strong> 来获取 ListState，也就是说每个 subtask 都可以获取到所有 partition 的offset 信息，然后根据分配器让 subtask 0 去消费 partition0 和 partition6 时，subtask0 只需要从全量的offset 中拿到 partition0 和 partition6 的状态信息即可。</p> <p>这么做会使得每个 subtask 获取到一些无用的 offset 的信息，但实际上这些 offset 信息占用的空间会比较小，所以该方案成本比较低。关于
OperatorState 的 ListState 两种获取方式请参考代码：</p> <blockquote><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-state/src/main/java/com/zhisheng/state/operator/state/UnionListStateExample.java" target="_blank" rel="noopener noreferrer">https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-state/src/main/java/com/zhisheng/state/operator/state/UnionListStateExample.java<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>FlinkKafkaConsumer 初始化时，恢复 offset 相关的源码如下：</p> <div class="language-java extra-class"><pre class="language-java"><code> <span class="token comment">// initializeState  方法中用于恢复 offset 状态信息</span>
    <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">initializeState</span><span class="token punctuation">(</span><span class="token class-name">FunctionInitializationContext</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token class-name">OperatorStateStore</span> stateStore <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getOperatorStateStore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 此处省略了兼容 Flink 1.2 之前状态 API 的场景</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token comment">// 此处使用的 getUnionListState，而不是 getListState。因为重启后，可能并行度被改变了</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>unionOffsetStates <span class="token operator">=</span> stateStore<span class="token punctuation">.</span><span class="token function">getUnionListState</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ListStateDescriptor</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>
                OFFSETS_STATE_NAME<span class="token punctuation">,</span>
                <span class="token class-name">TypeInformation</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TypeHint</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        <span class="token keyword">if</span> <span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">isRestored</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>restoredFromOldState<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            restoredState <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TreeMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">.</span><span class="token class-name">Comparator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
            <span class="token comment">// 将状态中恢复的 offset 信息 put 到 TreeMap 类型的 restoredState 中，方便查询</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> kafkaOffset <span class="token operator">:</span> unionOffsetStates<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                restoredState<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>kafkaOffset<span class="token punctuation">.</span>f0<span class="token punctuation">,</span> kafkaOffset<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>


    <span class="token comment">// open 方法对 FlinkKafkaConsumer 做初始化</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> configuration<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token comment">// 创建 Kafka partition 的发现器，用于检测该 subtask 应该去消费哪些 partition</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>partitionDiscoverer <span class="token operator">=</span> <span class="token function">createPartitionDiscoverer</span><span class="token punctuation">(</span>
                topicsDescriptor<span class="token punctuation">,</span>
                <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getIndexOfThisSubtask</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getNumberOfParallelSubtasks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>partitionDiscoverer<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// subscribedPartitionsToStartOffsets 存储当前 subtask 需要消费的 partition 及对应的 offset 初始信息</span>
        subscribedPartitionsToStartOffsets <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//用 partition 发现器获取该 subtask 应该消费且新发现的 partition</span>
        <span class="token keyword">final</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> allPartitions <span class="token operator">=</span> partitionDiscoverer<span class="token punctuation">.</span><span class="token function">discoverPartitions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// restoredState 在 initializeState 时初始化，所以 != null 表示任务从 Checkpoint 处恢复</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>restoredState <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">KafkaTopicPartition</span> partition <span class="token operator">:</span> allPartitions<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 若分配给该 subtask 的 partition 在 restoredState 中不包含</span>
                <span class="token comment">// 说明该 partition 是新创建的 partition，默认从 earliest 开始消费</span>
                  <span class="token comment">// 并添加到 restoredState 中</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>restoredState<span class="token punctuation">.</span><span class="token function">containsKey</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    restoredState<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>partition<span class="token punctuation">,</span> <span class="token class-name">KafkaTopicPartitionStateSentinel</span><span class="token punctuation">.</span>EARLIEST_OFFSET<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
    
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> restoredStateEntry <span class="token operator">:</span> restoredState<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 遍历 restoredState，使用分配器检测当前的 partition 是否分配给当前的 subtask</span>
                <span class="token comment">// assign 方法返回当前 partition 应该分配的 subtask index 编号</span>
                <span class="token comment">// getRuntimeContext().getIndexOfThisSubtask()  返回当前 subtask 的 index 编号</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">KafkaTopicPartitionAssigner</span><span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span>
                    restoredStateEntry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getNumberOfParallelSubtasks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                        <span class="token operator">==</span> <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getIndexOfThisSubtask</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
                    <span class="token comment">// 如果当前遍历的 partition 分配给当前 subtask 来消费，则将 partition 信息加到  subscribedPartitionsToStartOffsets 中</span>
                    subscribedPartitionsToStartOffsets<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>restoredStateEntry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> restoredStateEntry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
            <span class="token comment">// else 表示任务不是从 Checkpoint 处恢复，本次源码主要分析状态恢复，不考虑该情况</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
</code></pre></div><p>对 offset 信息快照相关的源码如下：</p> <div class="language-java extra-class"><pre class="language-java"><code> <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">snapshotState</span><span class="token punctuation">(</span><span class="token class-name">FunctionSnapshotContext</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token comment">// 把旧的 offset 信息从 unionOffsetStates 清除掉</span>
        unionOffsetStates<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        <span class="token keyword">final</span> <span class="token class-name">AbstractFetcher</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">&gt;</span></span> fetcher <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>kafkaFetcher<span class="token punctuation">;</span>
        <span class="token comment">// 通过提取器从 Kafka 读取数据，若 fetcher == null 表示提取器还未初始化</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>fetcher <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">// Kafka 提取器还未初始化，说明还未从 Kafka 中读取数据</span>
                    <span class="token comment">// 所以遍历 subscribedPartitionsToStartOffsets，将 offset 的初始信息写入到状态中</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> subscribedPartition <span class="token operator">:</span> subscribedPartitionsToStartOffsets<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                unionOffsetStates<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>subscribedPartition<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> subscribedPartition<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
    
            <span class="token keyword">if</span> <span class="token punctuation">(</span>offsetCommitMode <span class="token operator">==</span> <span class="token class-name">OffsetCommitMode</span><span class="token punctuation">.</span>ON_CHECKPOINTS<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 将 offset put 到 pendingOffsetsToCommit，后续 Commit 到 Kafka </span>
                pendingOffsetsToCommit<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">getCheckpointId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> restoredState<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
            <span class="token comment">// 从 Kafka 提取器中获取该 subtask 订阅的 partition 当前消费的 offset 信息</span>
            <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> currentOffsets <span class="token operator">=</span> fetcher<span class="token punctuation">.</span><span class="token function">snapshotCurrentState</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>offsetCommitMode <span class="token operator">==</span> <span class="token class-name">OffsetCommitMode</span><span class="token punctuation">.</span>ON_CHECKPOINTS<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 将 offset put 到 pendingOffsetsToCommit，后续 Commit 到 Kafka </span>
                pendingOffsetsToCommit<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">getCheckpointId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> currentOffsets<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
    
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> kafkaTopicPartitionLongEntry <span class="token operator">:</span> currentOffsets<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 将该 subtask 订阅的 partition 以及当前 partition 消费到的 offset 写入到状态中</span>
                unionOffsetStates<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>
                        <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>kafkaTopicPartitionLongEntry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kafkaTopicPartitionLongEntry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
</code></pre></div><p>上述源码分析描述了，当 Checkpoint 时 FlinkKafkaConsumer 如何将 offset 信息保存到状态中，当任务从
Checkpoint 处恢复时 FlinkKafkaConsumer 如何从状态中获取相应的 offset 信息，并解答了当 Source 并行度改变时
FlinkKafkaConsumer 如何来恢复 offset 信息。</p> <h4 id="如何实现自动发现当前消费-topic-下新增的-partition"><a href="#如何实现自动发现当前消费-topic-下新增的-partition" class="header-anchor">#</a> 如何实现自动发现当前消费 topic 下新增的 partition</h4> <p>当 FlinkKafkaConsumer 初始化时，每个 subtask 会订阅一批 partition，但是当 Flink 任务运行过程中，如果被订阅的
topic 创建了新的 partition，FlinkKafkaConsumer 如何实现动态发现新创建的 partition 并消费呢？</p> <p>在使用 FlinkKafkaConsumer 时，可以通过 Properties
传递一些配置参数，当配置了参数FlinkKafkaConsumerBase.KEY_PARTITION _DISCOVERY_INTERVAL_MILLIS 时，就会开启 partition 的动态发现，该参数表示间隔多久检测一次是否有新创建的 partition。那具体实现原理呢？相关源码的UML 图如下所示：</p> <p><img src="https://static.lovedata.net/zs/2019-11-15-132311.png" alt="images"></p> <p>笔者生产环境使用的 FlinkKafkaConsumer011，FlinkKafkaConsumer011 继承
FlinkKafkaConsumer09，FlinkKafkaConsumer09 继承 FlinkKafkaConsumerBase。将参数KEY_PARTITION <em>DISCOVERY_INTERVAL_MILLIS 传递给 FlinkKafkaConsumer011 时，在FlinkKafkaConsumer09 的构造器中会调用 getLong(checkNotNull(props, &quot;props&quot;),KEY_PARTITION_DISCOVERY_INTERVAL</em> MILLIS, PARTITION_DISCOVERY_DISABLED)
解析该参数，并最终赋值给 FlinkKafkaConsumerBase 的 discoveryIntervalMillis 属性。后续相关源码如下所示：</p> <div class="language-java extra-class"><pre class="language-java"><code> <span class="token comment">// FlinkKafkaConsumerBase 的 run 方法</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token class-name">SourceContext</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">&gt;</span></span> sourceContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>discoveryIntervalMillis <span class="token operator">==</span> PARTITION_DISCOVERY_DISABLED<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                kafkaFetcher<span class="token punctuation">.</span><span class="token function">runFetchLoop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
                <span class="token comment">// discoveryIntervalMillis 被设置了，则开启 PartitionDiscovery</span>
                <span class="token function">runWithPartitionDiscovery</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    
    <span class="token comment">// runWithPartitionDiscovery 方法会调用 createAndStartDiscoveryLoop 方法</span>
    <span class="token comment">// createAndStartDiscoveryLoop 方法内创建了一个线程去循环检测发现新分区</span>
    <span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">createAndStartDiscoveryLoop</span><span class="token punctuation">(</span><span class="token class-name">AtomicReference</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Exception</span><span class="token punctuation">&gt;</span></span> discoveryLoopErrorRef<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//  创建一个线程去循环检测发现新分区</span>
        discoveryLoopThread <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
            <span class="token keyword">while</span> <span class="token punctuation">(</span>running<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token keyword">final</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> discoveredPartitions<span class="token punctuation">;</span>
                <span class="token comment">//  用 partition 发现器获取该 subtask 应该消费且新发现的 partition</span>
                discoveredPartitions <span class="token operator">=</span> partitionDiscoverer<span class="token punctuation">.</span><span class="token function">discoverPartitions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
                <span class="token comment">// 发现了新的 partition，则添加到 Kafka 提取器</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>running <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>discoveredPartitions<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token comment">//  kafkaFetcher 添加 新发现的 partition</span>
                    kafkaFetcher<span class="token punctuation">.</span><span class="token function">addDiscoveredPartitions</span><span class="token punctuation">(</span>discoveredPartitions<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
    
                <span class="token keyword">if</span> <span class="token punctuation">(</span>running <span class="token operator">&amp;&amp;</span> discoveryIntervalMillis <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token comment">//  sleep 设置的间隔时间</span>
                    <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span>discoveryIntervalMillis<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">&quot;Kafka Partition Discovery for &quot;</span> <span class="token operator">+</span> <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTaskNameWithSubtasks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        discoveryLoopThread<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

</code></pre></div><p>discoveryLoopThread 线程中每间隔 discoveryIntervalMillis 时间会调用 partition 发现器获取该subtask 应该消费且新发现的 partition，在 open 方法初始化时，同样也调用 partitionDiscoverer.discoverPartitions() 方法来获取新发现的 partition，partition 发现器的
discoverPartitions 方法第一次调用时，会返回该 subtask 所有的 partition，后续调用只会返回新发现的且应该被当前subtask 消费的 partition。discoverPartitions 方法源码如下：</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> <span class="token function">discoverPartitions</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">WakeupException</span><span class="token punctuation">,</span> <span class="token class-name">ClosedException</span> <span class="token punctuation">{</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> newDiscoveredPartitions<span class="token punctuation">;</span>
        <span class="token comment">// 获取订阅的 Topic 的所有 partition </span>
        newDiscoveredPartitions <span class="token operator">=</span> <span class="token function">getAllPartitionsForTopics</span><span class="token punctuation">(</span>topicsDescriptor<span class="token punctuation">.</span><span class="token function">getFixedTopics</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        <span class="token comment">// 剔除 旧的 partition 和 不应该被该 subtask 去消费的 partition</span>
        <span class="token class-name">Iterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> iter <span class="token operator">=</span> newDiscoveredPartitions<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">KafkaTopicPartition</span> nextPartition<span class="token punctuation">;</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span>iter<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            nextPartition <span class="token operator">=</span> iter<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// setAndCheckDiscoveredPartition 方法设计比较巧妙，</span>
              <span class="token comment">// 将旧的 partition 和 不应该被该 subtask 消费的 partition，返回 false</span>
            <span class="token comment">// 将这些partition 剔除，就是新发现的 partition</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">setAndCheckDiscoveredPartition</span><span class="token punctuation">(</span>nextPartition<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                iter<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">return</span> newDiscoveredPartitions<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    
    <span class="token comment">// discoveredPartitions 中存放着所有发现的 partition</span>
    <span class="token keyword">private</span> <span class="token class-name">Set</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">KafkaTopicPartition</span><span class="token punctuation">&gt;</span></span> discoveredPartitions <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// setAndCheckDiscoveredPartition 方法实现</span>
    <span class="token comment">// 当参数的 partition 是新发现的 partition 且应该被当前 subtask 消费时，返回 true</span>
    <span class="token comment">// 旧的 partition 和 不应该被该 subtask 消费的 partition，返回 false</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">setAndCheckDiscoveredPartition</span><span class="token punctuation">(</span><span class="token class-name">KafkaTopicPartition</span> partition<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// discoveredPartitions 中不存在，表示发现了新的 partition，将其加入到 discoveredPartitions  </span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>discoveredPartitions<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            discoveredPartitions<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 再通过分配器来判断该 partition 是否应该被当前 subtask 去消费</span>
            <span class="token keyword">return</span> <span class="token class-name">KafkaTopicPartitionAssigner</span><span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span>partition<span class="token punctuation">,</span> numParallelSubtasks<span class="token punctuation">)</span> <span class="token operator">==</span> indexOfThisSubtask<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    
        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre></div><p>上述代码中依赖 Set 类型的 discoveredPartitions 来判断 partition 是否是新的 partition，刚开始discoveredPartitions 是一个空的 Set，所以任务初始化第一次调用发现器的 discoverPartitions方法时，会把所有属于当前 subtask 的 partition 都返回，来保证所有属于当前 subtask 的 partition都能被消费到。之后任务运行过程中，若创建了新的 partition，则新 partition 对应的那一个 subtask 会自动发现并从 earliest
位置开始消费，新创建的 partition 对其他 subtask 并不会产生影响。</p> <h3 id="小结与反思"><a href="#小结与反思" class="header-anchor">#</a> 小结与反思</h3> <p>本节分为三部分来讲述 Flink 如何保证 Exactly Once，第一部分讲了 Flink 内部如何保证 Exactly Once 并着重介绍了barrier 对齐。第二部分讲了端对端如何保证 Exactly Once，主要通过幂等性和两阶段提交两种方案。当出现故障时 Flink 任务要从Checkpoint 处恢复，所以在第三部分分析 FlinkKafkaConsumer 的实现原理，讲述了 FlinkKafkaConsumer 是如何维护offset 并从之前保存的 offset 处开始消费。你们平时设计的 Connector 能保证 Exactly Once 吗？</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/pengshuangbao/databook/edit/master/docs/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（下）.md" target="_blank" rel="noopener noreferrer">Edit this page on GitHub</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">2023/4/14 16:56:47</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（上）.html" class="prev">
        Flink中如何保证ExactlyOnce？（上）
      </a></span> <span class="next"><a href="/bigdata/flink/Flink实战与性能优化/如何处理Flink中数据倾斜问题？.html">
        如何处理Flink中数据倾斜问题？
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.0f56a723.js" defer></script><script src="/assets/js/4.a8ef5668.js" defer></script><script src="/assets/js/46.691097de.js" defer></script><script src="/assets/js/11.0473ae06.js" defer></script>
  </body>
</html>
