<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>基于Flink的海量日志实时处理系统的实践 | 编程手册</title>
    <meta name="generator" content="VuePress 1.7.1">
    <link rel="icon" href="/logo.png">
    <link rel="manifest" href="/manifest.json">
    <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#3eaf7c">
    <meta name="description" content="苍穹浩渺,取之须臾">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
    <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/assets/css/0.styles.225a8ff9.css" as="style"><link rel="preload" href="/assets/js/app.0f56a723.js" as="script"><link rel="preload" href="/assets/js/4.a8ef5668.js" as="script"><link rel="preload" href="/assets/js/57.b0cbba56.js" as="script"><link rel="preload" href="/assets/js/11.0473ae06.js" as="script"><link rel="prefetch" href="/assets/js/10.06cc4fbb.js"><link rel="prefetch" href="/assets/js/100.79e96d05.js"><link rel="prefetch" href="/assets/js/101.bcac0b9f.js"><link rel="prefetch" href="/assets/js/102.c5d92a95.js"><link rel="prefetch" href="/assets/js/103.697856ab.js"><link rel="prefetch" href="/assets/js/104.8f2db4d2.js"><link rel="prefetch" href="/assets/js/105.d4f2bb07.js"><link rel="prefetch" href="/assets/js/106.1a533c3f.js"><link rel="prefetch" href="/assets/js/107.b2845ea0.js"><link rel="prefetch" href="/assets/js/108.226e46ed.js"><link rel="prefetch" href="/assets/js/109.0de9c16c.js"><link rel="prefetch" href="/assets/js/110.4657c34b.js"><link rel="prefetch" href="/assets/js/111.3409d3a7.js"><link rel="prefetch" href="/assets/js/112.a46b486c.js"><link rel="prefetch" href="/assets/js/113.ba001fa9.js"><link rel="prefetch" href="/assets/js/114.ad1e6ba1.js"><link rel="prefetch" href="/assets/js/115.a0ac732f.js"><link rel="prefetch" href="/assets/js/116.4ee2a7b2.js"><link rel="prefetch" href="/assets/js/117.a76fd29a.js"><link rel="prefetch" href="/assets/js/118.83c5badf.js"><link rel="prefetch" href="/assets/js/119.09fec567.js"><link rel="prefetch" href="/assets/js/12.286e979d.js"><link rel="prefetch" href="/assets/js/120.42120fe1.js"><link rel="prefetch" href="/assets/js/121.9d79a9dd.js"><link rel="prefetch" href="/assets/js/122.f71a459c.js"><link rel="prefetch" href="/assets/js/123.b75308dc.js"><link rel="prefetch" href="/assets/js/124.e4d4643b.js"><link rel="prefetch" href="/assets/js/125.73fc990d.js"><link rel="prefetch" href="/assets/js/126.3b0eccd0.js"><link rel="prefetch" href="/assets/js/127.3eb3ab27.js"><link rel="prefetch" href="/assets/js/128.64ba68bb.js"><link rel="prefetch" href="/assets/js/129.82cfac7a.js"><link rel="prefetch" href="/assets/js/13.7207d991.js"><link rel="prefetch" href="/assets/js/130.42811f32.js"><link rel="prefetch" href="/assets/js/131.6f498e16.js"><link rel="prefetch" href="/assets/js/132.f0cc9ad2.js"><link rel="prefetch" href="/assets/js/133.325e755a.js"><link rel="prefetch" href="/assets/js/134.076a808c.js"><link rel="prefetch" href="/assets/js/135.fad7be83.js"><link rel="prefetch" href="/assets/js/136.042fc555.js"><link rel="prefetch" href="/assets/js/137.b67b55bc.js"><link rel="prefetch" href="/assets/js/138.6476c99f.js"><link rel="prefetch" href="/assets/js/139.ad07500f.js"><link rel="prefetch" href="/assets/js/14.a1cb7c1b.js"><link rel="prefetch" href="/assets/js/140.3edd2237.js"><link rel="prefetch" href="/assets/js/141.5181db27.js"><link rel="prefetch" href="/assets/js/142.67b4c4a2.js"><link rel="prefetch" href="/assets/js/143.9d249a3f.js"><link rel="prefetch" href="/assets/js/144.e6db5540.js"><link rel="prefetch" href="/assets/js/145.5b4305a7.js"><link rel="prefetch" href="/assets/js/146.bc674178.js"><link rel="prefetch" href="/assets/js/147.964ff3df.js"><link rel="prefetch" href="/assets/js/148.570b6864.js"><link rel="prefetch" href="/assets/js/149.4b9796c2.js"><link rel="prefetch" href="/assets/js/15.3cafda64.js"><link rel="prefetch" href="/assets/js/150.c677bf4b.js"><link rel="prefetch" href="/assets/js/151.b8977c93.js"><link rel="prefetch" href="/assets/js/152.535e2db4.js"><link rel="prefetch" href="/assets/js/153.754fc05e.js"><link rel="prefetch" href="/assets/js/154.5a5928b6.js"><link rel="prefetch" href="/assets/js/155.19893ca5.js"><link rel="prefetch" href="/assets/js/156.da1f2665.js"><link rel="prefetch" href="/assets/js/157.cb7b551f.js"><link rel="prefetch" href="/assets/js/158.f5d94a11.js"><link rel="prefetch" href="/assets/js/159.0b2b78d9.js"><link rel="prefetch" href="/assets/js/16.54ab9242.js"><link rel="prefetch" href="/assets/js/160.c2548b6c.js"><link rel="prefetch" href="/assets/js/161.8f694ed1.js"><link rel="prefetch" href="/assets/js/162.1adc1aa4.js"><link rel="prefetch" href="/assets/js/163.5688827c.js"><link rel="prefetch" href="/assets/js/164.8442474f.js"><link rel="prefetch" href="/assets/js/165.d0e21e5c.js"><link rel="prefetch" href="/assets/js/166.2e90ae99.js"><link rel="prefetch" href="/assets/js/167.374185de.js"><link rel="prefetch" href="/assets/js/168.2426769f.js"><link rel="prefetch" href="/assets/js/169.829516d9.js"><link rel="prefetch" href="/assets/js/17.9cad59f9.js"><link rel="prefetch" href="/assets/js/170.db0c4609.js"><link rel="prefetch" href="/assets/js/171.7bdcc41b.js"><link rel="prefetch" href="/assets/js/172.7f7ab109.js"><link rel="prefetch" href="/assets/js/173.c1d51df9.js"><link rel="prefetch" href="/assets/js/174.afa4c5f6.js"><link rel="prefetch" href="/assets/js/175.b46d9dd8.js"><link rel="prefetch" href="/assets/js/176.c38ba756.js"><link rel="prefetch" href="/assets/js/177.ba85b912.js"><link rel="prefetch" href="/assets/js/178.af1a44e8.js"><link rel="prefetch" href="/assets/js/179.e097e164.js"><link rel="prefetch" href="/assets/js/18.3776b09c.js"><link rel="prefetch" href="/assets/js/180.d9d5d80c.js"><link rel="prefetch" href="/assets/js/181.79401f8c.js"><link rel="prefetch" href="/assets/js/182.343db47f.js"><link rel="prefetch" href="/assets/js/183.005841bb.js"><link rel="prefetch" href="/assets/js/19.d0ac1e7f.js"><link rel="prefetch" href="/assets/js/20.e0100fb2.js"><link rel="prefetch" href="/assets/js/21.f59cd52c.js"><link rel="prefetch" href="/assets/js/22.3ecf54da.js"><link rel="prefetch" href="/assets/js/23.2508850b.js"><link rel="prefetch" href="/assets/js/24.0ac10322.js"><link rel="prefetch" href="/assets/js/25.7c3ee156.js"><link rel="prefetch" href="/assets/js/26.7021c42c.js"><link rel="prefetch" href="/assets/js/27.d716476b.js"><link rel="prefetch" href="/assets/js/28.58ebf808.js"><link rel="prefetch" href="/assets/js/29.88c37f6c.js"><link rel="prefetch" href="/assets/js/30.87bc4a91.js"><link rel="prefetch" href="/assets/js/31.a69c2a35.js"><link rel="prefetch" href="/assets/js/32.89f74912.js"><link rel="prefetch" href="/assets/js/33.df886872.js"><link rel="prefetch" href="/assets/js/34.835d0785.js"><link rel="prefetch" href="/assets/js/35.5e38ab06.js"><link rel="prefetch" href="/assets/js/36.5b639051.js"><link rel="prefetch" href="/assets/js/37.bb32ead0.js"><link rel="prefetch" href="/assets/js/38.c2541da0.js"><link rel="prefetch" href="/assets/js/39.3c8f0f06.js"><link rel="prefetch" href="/assets/js/40.4cc077aa.js"><link rel="prefetch" href="/assets/js/41.cbcd81a7.js"><link rel="prefetch" href="/assets/js/42.6d002f78.js"><link rel="prefetch" href="/assets/js/43.3f67c882.js"><link rel="prefetch" href="/assets/js/44.58ce7a4d.js"><link rel="prefetch" href="/assets/js/45.bfb9d6e0.js"><link rel="prefetch" href="/assets/js/46.691097de.js"><link rel="prefetch" href="/assets/js/47.e6b5c9b5.js"><link rel="prefetch" href="/assets/js/48.38159f5c.js"><link rel="prefetch" href="/assets/js/49.e03ce66a.js"><link rel="prefetch" href="/assets/js/5.340b4b76.js"><link rel="prefetch" href="/assets/js/50.7df345cb.js"><link rel="prefetch" href="/assets/js/51.b3eed5d5.js"><link rel="prefetch" href="/assets/js/52.bb282842.js"><link rel="prefetch" href="/assets/js/53.6b21ec8f.js"><link rel="prefetch" href="/assets/js/54.bab98944.js"><link rel="prefetch" href="/assets/js/55.59437904.js"><link rel="prefetch" href="/assets/js/56.18b88131.js"><link rel="prefetch" href="/assets/js/58.d9379002.js"><link rel="prefetch" href="/assets/js/59.e8663882.js"><link rel="prefetch" href="/assets/js/6.c48e1ddb.js"><link rel="prefetch" href="/assets/js/60.0a00b724.js"><link rel="prefetch" href="/assets/js/61.cd09980d.js"><link rel="prefetch" href="/assets/js/62.b092ff62.js"><link rel="prefetch" href="/assets/js/63.86482c79.js"><link rel="prefetch" href="/assets/js/64.3c1ee4d2.js"><link rel="prefetch" href="/assets/js/65.0621decf.js"><link rel="prefetch" href="/assets/js/66.cf7a6241.js"><link rel="prefetch" href="/assets/js/67.99e103bc.js"><link rel="prefetch" href="/assets/js/68.b3589f28.js"><link rel="prefetch" href="/assets/js/69.f0932a12.js"><link rel="prefetch" href="/assets/js/7.0f410b85.js"><link rel="prefetch" href="/assets/js/70.0a941773.js"><link rel="prefetch" href="/assets/js/71.3a6c6141.js"><link rel="prefetch" href="/assets/js/72.2299ff58.js"><link rel="prefetch" href="/assets/js/73.544fe8c6.js"><link rel="prefetch" href="/assets/js/74.98219c05.js"><link rel="prefetch" href="/assets/js/75.244a9d80.js"><link rel="prefetch" href="/assets/js/76.cefd9fe2.js"><link rel="prefetch" href="/assets/js/77.59793840.js"><link rel="prefetch" href="/assets/js/78.a7d9a079.js"><link rel="prefetch" href="/assets/js/79.f9ec013d.js"><link rel="prefetch" href="/assets/js/8.269955a4.js"><link rel="prefetch" href="/assets/js/80.b0f2cbe5.js"><link rel="prefetch" href="/assets/js/81.3d245e9a.js"><link rel="prefetch" href="/assets/js/82.061b170d.js"><link rel="prefetch" href="/assets/js/83.d2c42148.js"><link rel="prefetch" href="/assets/js/84.f6f487a4.js"><link rel="prefetch" href="/assets/js/85.c5305650.js"><link rel="prefetch" href="/assets/js/86.0c30a2ef.js"><link rel="prefetch" href="/assets/js/87.d9a99f2e.js"><link rel="prefetch" href="/assets/js/88.03792030.js"><link rel="prefetch" href="/assets/js/89.95684850.js"><link rel="prefetch" href="/assets/js/9.5c3462fb.js"><link rel="prefetch" href="/assets/js/90.185b012e.js"><link rel="prefetch" href="/assets/js/91.d19f0020.js"><link rel="prefetch" href="/assets/js/92.9e7855de.js"><link rel="prefetch" href="/assets/js/93.1ee902df.js"><link rel="prefetch" href="/assets/js/94.4bfab4ad.js"><link rel="prefetch" href="/assets/js/95.5f0b1d15.js"><link rel="prefetch" href="/assets/js/96.bd50a446.js"><link rel="prefetch" href="/assets/js/97.749fd671.js"><link rel="prefetch" href="/assets/js/98.bc09c746.js"><link rel="prefetch" href="/assets/js/99.40f98e75.js"><link rel="prefetch" href="/assets/js/vendors~flowchart.98d8c7d3.js"><link rel="prefetch" href="/assets/js/vendors~notification.5515ddcd.js">
    <link rel="stylesheet" href="/assets/css/0.styles.225a8ff9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">编程手册</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">
  算法 
</a></div><div class="nav-item"><a href="/architecture/" class="nav-link">
  架构 
</a></div><div class="nav-item"><a href="/computer/" class="nav-link">
  计算机 
</a></div><div class="nav-item"><a href="/database/" class="nav-link">
  数据库 
</a></div><div class="nav-item"><a href="/fe/" class="nav-link">
  前端
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维 " class="dropdown-title"><span class="title">运维 </span> <span class="arrow down"></span></button> <button type="button" aria-label="运维 " class="mobile-dropdown-title"><span class="title">运维 </span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ops/" class="nav-link">
  基础
</a></li><li class="dropdown-item"><h4>
          分类
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ops/java.html" class="nav-link">
  Java
</a></li><li class="dropdown-subitem"><a href="/ops/bigdata.html" class="nav-link">
  大数据
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程" class="dropdown-title"><span class="title">编程</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程" class="mobile-dropdown-title"><span class="title">编程</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          语言
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/programming/python.html" class="nav-link">
  Python
</a></li><li class="dropdown-subitem"><a href="/programming/scala.html" class="nav-link">
  Scala
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="资源" class="dropdown-title"><span class="title">资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="资源" class="mobile-dropdown-title"><span class="title">资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          我的书单
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/tech.html" class="nav-link">
  技术类
</a></li><li class="dropdown-subitem"><a href="/book/growth.html" class="nav-link">
  成长类
</a></li></ul></li><li class="dropdown-item"><h4>
          网课
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/geek.html" class="nav-link">
  专栏
</a></li><li class="dropdown-subitem"><a href="/book/video.html" class="nav-link">
  视频
</a></li></ul></li><li class="dropdown-item"><h4>
          面经
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/interview/tech.html" class="nav-link">
  大厂面经
</a></li><li class="dropdown-subitem"><a href="/interview/sword-to-offer.html" class="nav-link">
  剑指Offer
</a></li><li class="dropdown-subitem"><a href="/interview/fe.html" class="nav-link">
  前端面经
</a></li><li class="dropdown-subitem"><a href="/interview/interview_guide.html" class="nav-link">
  面试导航
</a></li></ul></li><li class="dropdown-item"><h4>
          其他
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/study.html" class="nav-link">
  学习笔记
</a></li></ul></li></ul></div></div> <a href="https://github.com/pengshuangbao/databook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">
  算法 
</a></div><div class="nav-item"><a href="/architecture/" class="nav-link">
  架构 
</a></div><div class="nav-item"><a href="/computer/" class="nav-link">
  计算机 
</a></div><div class="nav-item"><a href="/database/" class="nav-link">
  数据库 
</a></div><div class="nav-item"><a href="/fe/" class="nav-link">
  前端
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维 " class="dropdown-title"><span class="title">运维 </span> <span class="arrow down"></span></button> <button type="button" aria-label="运维 " class="mobile-dropdown-title"><span class="title">运维 </span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ops/" class="nav-link">
  基础
</a></li><li class="dropdown-item"><h4>
          分类
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ops/java.html" class="nav-link">
  Java
</a></li><li class="dropdown-subitem"><a href="/ops/bigdata.html" class="nav-link">
  大数据
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程" class="dropdown-title"><span class="title">编程</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程" class="mobile-dropdown-title"><span class="title">编程</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          语言
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/programming/python.html" class="nav-link">
  Python
</a></li><li class="dropdown-subitem"><a href="/programming/scala.html" class="nav-link">
  Scala
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="资源" class="dropdown-title"><span class="title">资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="资源" class="mobile-dropdown-title"><span class="title">资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          我的书单
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/tech.html" class="nav-link">
  技术类
</a></li><li class="dropdown-subitem"><a href="/book/growth.html" class="nav-link">
  成长类
</a></li></ul></li><li class="dropdown-item"><h4>
          网课
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/geek.html" class="nav-link">
  专栏
</a></li><li class="dropdown-subitem"><a href="/book/video.html" class="nav-link">
  视频
</a></li></ul></li><li class="dropdown-item"><h4>
          面经
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/interview/tech.html" class="nav-link">
  大厂面经
</a></li><li class="dropdown-subitem"><a href="/interview/sword-to-offer.html" class="nav-link">
  剑指Offer
</a></li><li class="dropdown-subitem"><a href="/interview/fe.html" class="nav-link">
  前端面经
</a></li><li class="dropdown-subitem"><a href="/interview/interview_guide.html" class="nav-link">
  面试导航
</a></li></ul></li><li class="dropdown-item"><h4>
          其他
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/study.html" class="nav-link">
  学习笔记
</a></li></ul></li></ul></div></div> <a href="https://github.com/pengshuangbao/databook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/bigdata/" aria-current="page" class="sidebar-link">大数据</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Hadoop</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spark</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Flink</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/flink/" aria-current="page" class="sidebar-link">Flink</a></li><li><a href="/bigdata/flink/通关手册.html" class="sidebar-link">通关手册</a></li><li><a href="/bigdata/flink/学习资源.html" class="sidebar-link">学习资源</a></li><li><a href="/bigdata/flink/开源动态.html" class="sidebar-link">开源动态</a></li><li><a href="/bigdata/flink/Flink状态原理.html" class="sidebar-link">状态原理</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Flink实战与性能优化</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/flink/Flink实战与性能优化/公司到底需不需要引入实时计算引擎？.html" class="sidebar-link">公司到底需不需要引入实时计算引擎？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/彻底了解大数据实时计算框架Flink.html" class="sidebar-link">彻底了解大数据实时计算框架Flink</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/大数据框架Flink、Blink、SparkStreaming、StructuredStreaming和Storm之间的区别.html" class="sidebar-link">大数据框架Flink、Blink、SparkStreaming、StructuredStreaming和Storm之间的区别</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink环境准备.html" class="sidebar-link">Flink环境准备</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink环境搭建.html" class="sidebar-link">Flink环境搭建</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWordCount应用程序.html" class="sidebar-link">FlinkWordCount应用程序</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink实时处理Socket数据.html" class="sidebar-link">Flink实时处理Socket数据</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink多种时间语义对比.html" class="sidebar-link">Flink多种时间语义对比</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWindow基础概念与实现原理.html" class="sidebar-link">FlinkWindow基础概念与实现原理</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/数据转换必须熟悉的算子（Operator）.html" class="sidebar-link">数据转换必须熟悉的算子（Operator）</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用DataStreamAPI来处理数据？.html" class="sidebar-link">如何使用DataStreamAPI来处理数据？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkWaterMark详解及结合WaterMark处理延迟数据.html" class="sidebar-link">FlinkWaterMark详解及结合WaterMark处理延迟数据</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink常用的Source和SinkConnectors介绍.html" class="sidebar-link">Flink常用的Source和SinkConnectors介绍</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkConnectorKafka使用和剖析.html" class="sidebar-link">FlinkConnectorKafka使用和剖析</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何自定义FlinkConnectors（Source和Sink）？.html" class="sidebar-link">如何自定义FlinkConnectors（Source和Sink）？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——ElasticSearch？.html" class="sidebar-link">如何使用FlinkConnectors——ElasticSearch？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——HBase？.html" class="sidebar-link">如何使用FlinkConnectors——HBase？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkConnectors——Redis？.html" class="sidebar-link">如何使用FlinkConnectors——Redis？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用SideOutput来分流.html" class="sidebar-link">如何使用SideOutput来分流</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkState深度讲解.html" class="sidebar-link">FlinkState深度讲解</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何选择Flink状态后端存储.html" class="sidebar-link">如何选择Flink状态后端存储</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCheckpoint和Savepoint区别及其如何配置使用？.html" class="sidebar-link">FlinkCheckpoint和Savepoint区别及其如何配置使用？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkTable&amp;SQL概念与通用API.html" class="sidebar-link">FlinkTable&amp;SQL概念与通用API</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkTableAPI&amp;SQL功能.html" class="sidebar-link">FlinkTableAPI&amp;SQL功能</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCEP介绍及其使用场景.html" class="sidebar-link">FlinkCEP介绍及其使用场景</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkCEP如何处理复杂事件？.html" class="sidebar-link">FlinkCEP如何处理复杂事件？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——StateProcessorAPI.html" class="sidebar-link">Flink扩展库——StateProcessorAPI</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——MachineLearning.html" class="sidebar-link">Flink扩展库——MachineLearning</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink扩展库——Gelly.html" class="sidebar-link">Flink扩展库——Gelly</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink配置详解及如何配置高可用？.html" class="sidebar-link">Flink配置详解及如何配置高可用？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkJob如何在Standalone、YARN、Mesos、K8S上部署运行？.html" class="sidebar-link">FlinkJob如何在Standalone、YARN、Mesos、K8S上部署运行？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何实时监控Flink和你的Job？.html" class="sidebar-link">如何实时监控Flink和你的Job？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何搭建一套完整的Flink监控系统.html" class="sidebar-link">如何搭建一套完整的Flink监控系统</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何处理FlinkJobBackPressure（反压）问题？.html" class="sidebar-link">如何处理FlinkJobBackPressure（反压）问题？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何查看FlinkJob执行计划？.html" class="sidebar-link">如何查看FlinkJob执行计划？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/FlinkParallelism和Slot深度理解.html" class="sidebar-link">FlinkParallelism和Slot深度理解</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何合理的设置FlinkJob并行度？.html" class="sidebar-link">如何合理的设置FlinkJob并行度？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（上）.html" class="sidebar-link">Flink中如何保证ExactlyOnce？（上）</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/Flink中如何保证ExactlyOnce？（下）.html" class="sidebar-link">Flink中如何保证ExactlyOnce？（下）</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何处理Flink中数据倾斜问题？.html" class="sidebar-link">如何处理Flink中数据倾斜问题？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何设置FlinkJobRestartStrategy（重启策略）？.html" class="sidebar-link">如何设置FlinkJobRestartStrategy（重启策略）？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkParameterTool读取配置？.html" class="sidebar-link">如何使用FlinkParameterTool读取配置？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何统计网站各页面一天内的PV和UV？.html" class="sidebar-link">如何统计网站各页面一天内的PV和UV？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何使用FlinkProcessFunction处理宕机告警.html" class="sidebar-link">如何使用FlinkProcessFunction处理宕机告警</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何利用AsyncIO读取告警规则？.html" class="sidebar-link">如何利用AsyncIO读取告警规则？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何利用广播变量动态更新告警规则？.html" class="sidebar-link">如何利用广播变量动态更新告警规则？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/如何实时将应用Error日志告警？.html" class="sidebar-link">如何实时将应用Error日志告警？</a></li><li><a href="/bigdata/flink/Flink实战与性能优化/基于Flink的海量日志实时处理系统的实践.html" class="active sidebar-link">基于Flink的海量日志实时处理系统的实践</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/bigdata/flink/Flink实战与性能优化/基于Flink的百亿数据去重实践.html" class="sidebar-link">基于Flink的百亿数据去重实践</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kylin</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kafka</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Hbase</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>ClickHouse</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Impala</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kudu</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Redis</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>hive</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/bigdata/zookeeper.html" class="sidebar-link">Zookeeper</a></li><li><a href="/bigdata/solution.html" class="sidebar-link">解决方案</a></li><li><a href="/bigdata/design.html" class="sidebar-link">编程设计</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="基于flink的海量日志实时处理系统的实践"><a href="#基于flink的海量日志实时处理系统的实践" class="header-anchor">#</a> 基于Flink的海量日志实时处理系统的实践</h1> <p></p><div class="table-of-contents"><ul><li><a href="#海量日志实时处理需求分析">海量日志实时处理需求分析</a></li><li><a href="#海量日志实时处理架构设计">海量日志实时处理架构设计</a></li><li><a href="#日志实时采集">日志实时采集</a><ul><li><a href="#安装-filebeat">安装 Filebeat</a></li><li><a href="#配置-filebeat">配置 Filebeat</a></li><li><a href="#启动-filebeat">启动 Filebeat</a></li><li><a href="#验证-filebeat-是否将日志数据发到-kafka">验证 Filebeat 是否将日志数据发到 Kafka</a></li><li><a href="#发到-kafka-的日志结构">发到 Kafka 的日志结构</a></li></ul></li><li><a href="#日志格式统一">日志格式统一</a></li><li><a href="#日志实时清洗">日志实时清洗</a></li><li><a href="#日志实时告警">日志实时告警</a></li><li><a href="#日志实时存储">日志实时存储</a></li><li><a href="#日志实时展示">日志实时展示</a></li><li><a href="#小结与反思">小结与反思</a></li></ul></div><p></p> <h3 id="海量日志实时处理需求分析"><a href="#海量日志实时处理需求分析" class="header-anchor">#</a> 海量日志实时处理需求分析</h3> <p>在 11.5 节中讲解了 Flink
如何实时处理异常的日志，在那节中对比分析了几种常用的日志采集工具。我们也知道通常在排查线上异常故障的时候，查询日志总是必不可缺的一部分，但是现在微服务架构下日志都被分散到不同的机器上，日志查询就会比较困难，所以统一的日志收集几乎也是每家公司必不可少的。据笔者调研，不少公司现在是有日志统一的收集，也会去做日志的实时
ETL，利用一些主流的技术比如 ELK
去做日志的展示、搜索和分析，但是却缺少了日志的实时告警。在本节中，笔者将为大家做一个全方位的日志链路讲解，包含了日志的实时采集、日志的
ETL、日志的实时监控告警、日志的存储、日志的可视化图表展示与搜索分析等。</p> <h3 id="海量日志实时处理架构设计"><a href="#海量日志实时处理架构设计" class="header-anchor">#</a> 海量日志实时处理架构设计</h3> <p>分析完我们这个案例的需求后，接下来对整个项目的架构做一个合理的设计。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-145059.png" alt="images">
整个架构分为五层：日志接入层、日志削峰层、日志处理层、日志存储层、日志展示层。</p> <ul><li>日志接入层：日志采集的话使用的是 Filebeat 组件，需要在每台机器上部署一个 Filebeat。</li> <li>日志削峰层：防止日志流量高峰，使用 Kafka 消息队列做削峰。</li> <li>日志处理层：Flink 作业同时消费 Kafka 数据做日志清洗、ETL、实时告警。</li> <li>日志存储层：使用 ElasticSearch 做日志的存储。</li> <li>日志展示层：使用 Kibana 做日志的展示与搜索查询界面。</li></ul> <h3 id="日志实时采集"><a href="#日志实时采集" class="header-anchor">#</a> 日志实时采集</h3> <p>在 11.5.1
中对比了这几种比较流行的日志采集工具（Logstash、Filebeat、Fluentd、Logagent），从功能完整性、性能、成本、使用难度等方面综合考虑后，这里演示使用的是
Filebeat。</p> <h4 id="安装-filebeat"><a href="#安装-filebeat" class="header-anchor">#</a> 安装 Filebeat</h4> <p>在服务器上下载 <a href="https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz" target="_blank" rel="noopener noreferrer">Fliebeat
6.3.2<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
安装包（请根据自己服务器和所需要的版本进行下载），下载后进行解压。</p> <p>​<br>
tar xzf filebeat-6.3.2-linux-x86_64.tar.gz</p> <h4 id="配置-filebeat"><a href="#配置-filebeat" class="header-anchor">#</a> 配置 Filebeat</h4> <p>配置 Filebeat 需要编辑 Filebeat
的配置文件（filebeat.yml），不同安装方式配置文件的存放路径有一些不同，对于解压包安装的方式，配置文件存在解压目录下面；对于 rpm 和 deb
的方式, 配置文件路径的是 /etc/filebeat/filebeat.yml 下。</p> <p>因为 Filebeat 是要实时采集日志的，所以得让 Filebeat
知道日志的路径是在哪里，下面在配置文件中定义一下日志文件的路径。通常建议在服务器上固定存放日志的路径，然后应用的日志都打在这个固定的路径中，这样
Filebeat 的日志路径配置只需要填写一次，其他机器上可以拷贝同样的配置就能将 Filebeat 运行起来，配置如下。</p> <p>​</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> log
  <span class="token comment"># 配置为 true 表示开启</span>
  <span class="token key atrule">enabled</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
  <span class="token comment"># 日志的路径</span>
  <span class="token key atrule">paths</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> /var/logs/<span class="token important">*.log</span>
</code></pre></div><p>上面的配置表示将对 /var/logs 目录下所有以 .log 结尾的文件进行采集，接下来配置日志输出的方式，这里使用的是 Kafka，配置如下。</p> <p>​</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">output.kafka</span><span class="token punctuation">:</span>
  <span class="token comment"># 填写 Kafka 地址信息</span>
  <span class="token key atrule">hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">]</span>
  <span class="token comment"># 数据发到哪个 topic</span>
  <span class="token key atrule">topic</span><span class="token punctuation">:</span> zhisheng<span class="token punctuation">-</span>log
  <span class="token key atrule">partition.round_robin</span><span class="token punctuation">:</span>
    <span class="token key atrule">reachable_only</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>
  <span class="token key atrule">required_acks</span><span class="token punctuation">:</span> <span class="token number">1</span>
</code></pre></div><p>上面讲解的两个配置，笔者这里将它们写在一个新建的配置文件中 kafka.yml，然后启动 Filebeat 的时候使用该配置。</p> <p>​</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">filebeat.inputs</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> log
  <span class="token key atrule">enabled</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
  <span class="token key atrule">paths</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> /var/logs/<span class="token important">*.log</span>
<span class="token key atrule">output.kafka</span><span class="token punctuation">:</span>
  <span class="token key atrule">hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;localhost:9092&quot;</span><span class="token punctuation">]</span>
  <span class="token key atrule">topic</span><span class="token punctuation">:</span> zhisheng_log
  <span class="token key atrule">partition.round_robin</span><span class="token punctuation">:</span>
    <span class="token key atrule">reachable_only</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>
  <span class="token key atrule">required_acks</span><span class="token punctuation">:</span> <span class="token number">1</span>
</code></pre></div><h4 id="启动-filebeat"><a href="#启动-filebeat" class="header-anchor">#</a> 启动 Filebeat</h4> <p>日志路径的配置和 Kafka 的配置都写好后，则接下来通过下面命令将 Filebeat 启动：</p> <p>​</p> <div class="language-shell extra-class"><pre class="language-shell"><code>bin/filebeat -e -c kafka.yml
</code></pre></div><p>执行完命令后出现的日志如下则表示启动成功了，另外还可以看得到会在终端打印出 metrics 数据出来。</p> <p><img src="https://static.lovedata.net/zs/2019-10-26-075438.png" alt="images"></p> <h4 id="验证-filebeat-是否将日志数据发到-kafka"><a href="#验证-filebeat-是否将日志数据发到-kafka" class="header-anchor">#</a> 验证 Filebeat 是否将日志数据发到 Kafka</h4> <p>那么此时就得去查看是否真正就将这些日志数据发到 Kafka 了呢，你可以通过 Kafka 的自带命令去消费这个 Topic
看是否不断有数据发出来，命令如下：</p> <p>​</p> <div class="language-shell extra-class"><pre class="language-shell"><code>bin/kafka-console-consumer.sh --zookeeper <span class="token number">106.54</span>.248.27:2181 --topic zhisheng_log --from-beginning
</code></pre></div><p>如果出现数据则代表是已经有数据发到 Kafka 了，如果你不喜欢使用这种方式验证，可以自己写个 Flink Job 去读取 Kafka 该 Topic
的数据，比如写了个作业运行结果如下就代表着日志数据已经成功发送到 Kafka。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-150039.png" alt="images"></p> <h4 id="发到-kafka-的日志结构"><a href="#发到-kafka-的日志结构" class="header-anchor">#</a> 发到 Kafka 的日志结构</h4> <p>既然数据都已经发到 Kafka 了，通过消费 Kafka 该 Topic 的数据我们可以发现这些数据的格式否是 JSON，结构如下：</p> <p>​</p> <div class="language-json extra-class"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;@timestamp&quot;</span><span class="token operator">:</span> <span class="token string">&quot;2019-10-26T08:18:18.087Z&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;@metadata&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;beat&quot;</span><span class="token operator">:</span> <span class="token string">&quot;filebeat&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;doc&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;6.8.4&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;topic&quot;</span><span class="token operator">:</span> <span class="token string">&quot;zhisheng_log&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;prospector&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;log&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;input&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;log&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;beat&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;VM_0_2_centos&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;hostname&quot;</span><span class="token operator">:</span> <span class="token string">&quot;VM_0_2_centos&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;6.8.4&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;VM_0_2_centos&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;source&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/var/logs/middleware/kafka.log&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;offset&quot;</span><span class="token operator">:</span> <span class="token number">9460</span><span class="token punctuation">,</span>
    <span class="token property">&quot;log&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;file&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;path&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/var/logs/middleware/kafka.log&quot;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;message&quot;</span><span class="token operator">:</span> <span class="token string">&quot;2019-10-26 16:18:11 TRACE [Controller id=0] Leader imbalance ratio for broker 0 is 0.0 (kafka.controller.KafkaController)&quot;</span>
<span class="token punctuation">}</span>
</code></pre></div><p>这个日志结构里面包含了很多字段，比如 timestamp、metadata、host、source、message
等，但是其中某些字段我们其实根本不需要的，你可以根据公司的需求丢弃一些字段，把要丢弃的字段也配置在 kafka.yml 中，如下所示。</p> <p>​</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">processors</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">drop_fields</span><span class="token punctuation">:</span>
    <span class="token key atrule">fields</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;prospector&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;beat&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;log&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;offset&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;@metadata&quot;</span><span class="token punctuation">]</span>
</code></pre></div><p>然后再次启动 Filebeat ，发现上面配置的字段在新的数据中没有了（除 @metadata 之外），另外经笔者验证：不仅 @metadata
字段不能丢弃，如果 @timestamp 这个字段在 drop_fields
中配置了，也是不起作用的，它们两不允许丢弃。通常来说一行日志已经够长了，再加上这么多我们不需要的字段，就会增加数据的大小，对于生产环境的话，日志数据量非常大，那无疑会对后面所有的链路都会造成一定的影响，所以一定要在底层数据源头做好精简。另外还可以在发送
Kafka 的时候对数据进行压缩，可以在配置文件中配置一个 <code>compression: gzip</code>。精简后的日志数据结构如下：</p> <p>​</p> <div class="language-json extra-class"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;@timestamp&quot;</span><span class="token operator">:</span> <span class="token string">&quot;2019-10-26T09:23:16.848Z&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;@metadata&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;beat&quot;</span><span class="token operator">:</span> <span class="token string">&quot;filebeat&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;doc&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;6.8.4&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;topic&quot;</span><span class="token operator">:</span> <span class="token string">&quot;zhisheng_log&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;VM_0_2_centos&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;source&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/var/logs/middleware/kafka.log&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;message&quot;</span><span class="token operator">:</span> <span class="token string">&quot;2019-10-26 17:23:11 TRACE [Controller id=0] Leader imbalance ratio for broker 0 is 0.0 (kafka.controller.KafkaController)&quot;</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="日志格式统一"><a href="#日志格式统一" class="header-anchor">#</a> 日志格式统一</h3> <p>因为 Filebeat
是在机器上采集的日志，这些日志的种类比较多，常见的有应用程序的运行日志、作业构建编译打包的日志、中间件服务运行的日志等。通常在公司是可以给开发约定日志打印的规则，但是像中间件这类服务的日志是不固定的，如果将
Kafka 中的消息直接存储到 ElasticSearch 的话，后面如果要做区分筛选的话可能会有问题。为了避免这个问题，我们得在日志存入
ElasticSearch 之前做一个数据格式化和清洗的工作，因为 Flink 处理数据的速度比较好，而且可以做到实时，所以选择在 Flink Job
中完成该工作。</p> <p>在该作业中的要将 message 解析，一般该行日志信息会包含很多信息，比如日志打印时间、日志级别、应用名、唯一性
ID（用来关联各个请求）、请求上下文。那么我们就需要一个新的日志结构对象来统一日志的格式，定义如下：</p> <p>​</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogEvent</span> <span class="token punctuation">{</span>
    <span class="token comment">//日志的类型</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> type<span class="token punctuation">;</span>

    <span class="token comment">//日志的时间戳</span>
    <span class="token keyword">private</span> <span class="token class-name">Long</span> timestamp<span class="token punctuation">;</span>

    <span class="token comment">//日志的级别</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> level<span class="token punctuation">;</span>

    <span class="token comment">//日志的内容</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> message<span class="token punctuation">;</span>

    <span class="token comment">//日志的一些标签，需要解析原数据中的 message 字段获取。例如日志所在的机器、日志文件名、应用名、应用 id 等</span>
    <span class="token keyword">private</span> <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> tags <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="日志实时清洗"><a href="#日志实时清洗" class="header-anchor">#</a> 日志实时清洗</h3> <p>日志数据已经可以通过 Filebeat 实时发送到 Kafka 了，在 Flink
中也可以消费到日志数据，接下来要做的就是将日志数据做实时的清洗，将其原始结构转换成 LogEvent，那么其主要的工作在于解析原始数据中的 message
字段，将时间、日志级别、应用信息等存放在 tags 里面。比如下面这条日志，它的格式就是 <code>date(时间) log-level（日志级别） log- message（日志内容）</code>。</p> <p>​<br>
2019-10-26 19:53:05 INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)</p> <p>通常使用正则表达式解析日志比较多，这里我们使用 grok（基于正则表达式）来解析这种日志内容，像上面这条日志的正则表达式结构如下：</p> <p>​<br>
%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{JAVALOGMESSAGE:logmessage}</p> <p>要在 Java 项目中使用 grok，需要先引入依赖，关于使用哪种依赖可以先去 GitHub 查阅一下，这里我们使用的是 java-grok。</p> <p>​</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>io.krakens<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>java-grok<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>0.1.9<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>在测试之前需要先在配置文件中加入相关的正则表达式 pattern 文件，这个文件可以在 GitHub
下载，如果不满足我们现在日志的格式，那么得需要自己再额外在文件中定义一个我们日志的正则表达式，笔者这里定义的如下：</p> <p>​<br>
# 2019-10-26 19:53:05 INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
KAFKALOG %{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{JAVALOGMESSAGE:logmessage}</p> <p>通常在一家公司的日志格式虽然可以尽量的统一，但难免还是会有开发不会按照规定来打印日志，所以这种情况得根据实际场景去匹配不同的正则表达式，然后来解析这些日志。本节因测试，我们就暂定日志格式如上面这种，接下来笔者写了个
GrokUtil 工具类，它提供了一个 toMap 方法将日志 message 根据定义的 pattern 来解析数据成一个 <code>Map&lt;String, Object&gt;</code> 对象，这样后面就可以直接利用该方法解析日志的 message。</p> <p>​</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code>public static final GrokCompiler compiler = GrokCompiler.newInstance();
public static Grok grok = null;

public static Map&lt;String<span class="token punctuation">,</span> Object<span class="token punctuation">&gt;</span> toMap(String pattern<span class="token punctuation">,</span> String message) <span class="token punctuation">{</span>
    compiler.registerPatternFromClasspath(&quot;/patterns/patterns&quot;);//配置文件的正则表达式
    grok = compiler.compile(pattern);
    if (grok <span class="token tag">!=</span> null) <span class="token punctuation">{</span>
        Match match = grok.match(message);
        return match.capture();
    <span class="token punctuation">}</span> else <span class="token punctuation">{</span>
        return new HashMap&lt;<span class="token punctuation">&gt;</span>();
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>前面提供的那条日志通过上面的方法解析后的 <code>Map&lt;String, Object&gt;</code> 对象如下。</p> <p>​<br>
{YEAR=2019, MONTHNUM=10, HOUR=[19, null], level=INFO, logmessage=[GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager), MINUTE=[53, null], SECOND=05.929, ISO8601_TIMEZONE=null, KAFKALOG=2019-10-26 19:53:05.929 INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager), MONTHDAY=26, timestamp=2019-10-26 19:53:05}</p> <p>可以发现 level、timestamp 等信息我们可以获取到了，接下来就是将原始的日志结构类型转换成 LogEvent 的格式，代码如下：</p> <p>​</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OriLog2LogEventFlatMapFunction</span> <span class="token keyword">extends</span> <span class="token class-name">RichFlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">OriginalLogEvent</span><span class="token punctuation">,</span> <span class="token class-name">LogEvent</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">OriginalLogEvent</span> originalLogEvent<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LogEvent</span><span class="token punctuation">&gt;</span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>originalLogEvent <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">return</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token class-name">LogEvent</span> logEvent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogEvent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> source <span class="token operator">=</span> originalLogEvent<span class="token punctuation">.</span><span class="token function">getSource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>source<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">&quot;middleware&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            logEvent<span class="token punctuation">.</span><span class="token function">setType</span><span class="token punctuation">(</span><span class="token string">&quot;MIDDLEWARE&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>source<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">&quot;app&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
            logEvent<span class="token punctuation">.</span><span class="token function">setType</span><span class="token punctuation">(</span><span class="token string">&quot;APP&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>source<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">&quot;docker&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            logEvent<span class="token punctuation">.</span><span class="token function">setType</span><span class="token punctuation">(</span><span class="token string">&quot;DOCKER&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
            logEvent<span class="token punctuation">.</span><span class="token function">setType</span><span class="token punctuation">(</span><span class="token string">&quot;MACHINE&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        logEvent<span class="token punctuation">.</span><span class="token function">setMessage</span><span class="token punctuation">(</span>originalLogEvent<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">&gt;</span></span> messageMap <span class="token operator">=</span> <span class="token class-name">GrokUtil</span><span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span><span class="token string">&quot;%{KAFKALOG}&quot;</span><span class="token punctuation">,</span> originalLogEvent<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        logEvent<span class="token punctuation">.</span><span class="token function">setTimestamp</span><span class="token punctuation">(</span><span class="token class-name">DateUtil</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>messageMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">&quot;timestamp&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> YYYY_MM_DD_HH_MM_SS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        logEvent<span class="token punctuation">.</span><span class="token function">setLevel</span><span class="token punctuation">(</span>messageMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">&quot;level&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> tags <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tags<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;host_name&quot;</span><span class="token punctuation">,</span> originalLogEvent<span class="token punctuation">.</span><span class="token function">getHost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tags<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;kafka_tpoic&quot;</span><span class="token punctuation">,</span> originalLogEvent<span class="token punctuation">.</span><span class="token function">getMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">&quot;topic&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tags<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;source&quot;</span><span class="token punctuation">,</span> originalLogEvent<span class="token punctuation">.</span><span class="token function">getSource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//可以添加更多 message 解析出来的字段放在该 tags 里面</span>

        logEvent<span class="token punctuation">.</span><span class="token function">setTags</span><span class="token punctuation">(</span>tags<span class="token punctuation">)</span><span class="token punctuation">;</span>
        collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>logEvent<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>到上面这步的话，差不多就把数据获取和数据的清洗已经完成了，接下来的工作就是要完成日志的实时告警和日志的实时存储了，所以笔者的项目代码搭建如下：</p> <p>​</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogMain</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token keyword">final</span> <span class="token class-name">ParameterTool</span> parameterTool <span class="token operator">=</span> <span class="token class-name">ExecutionEnvUtil</span><span class="token punctuation">.</span><span class="token function">createParameterTool</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">ExecutionEnvUtil</span><span class="token punctuation">.</span><span class="token function">prepare</span><span class="token punctuation">(</span>parameterTool<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LogEvent</span><span class="token punctuation">&gt;</span></span> logDataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer011</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token string">&quot;zhisheng_log&quot;</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">OriginalLogEventSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token function">buildKafkaProps</span><span class="token punctuation">(</span>parameterTool<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OriLog2LogEventFlatMapFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//alert</span>
        <span class="token class-name">LogAlert</span><span class="token punctuation">.</span><span class="token function">alert</span><span class="token punctuation">(</span>logDataStream<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//sink to es</span>
        <span class="token class-name">LogSink2ES</span><span class="token punctuation">.</span><span class="token function">sink2es</span><span class="token punctuation">(</span>logDataStream<span class="token punctuation">)</span><span class="token punctuation">;</span>

        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">&quot;flink learning monitor log&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="日志实时告警"><a href="#日志实时告警" class="header-anchor">#</a> 日志实时告警</h3> <p>通常公司的业务会很多，所以应用也会很多，那么在应用这么多的情况下，其实开发是没有很多一直去盯着应用的运行状态，但是应用的运行状态又关系到业务的稳定，所以当应用有问题的时候其实很希望能够立马收到通知，这样就可以及时去处理问题，以免造成更大的影响，这时，告警通知就起作用了。</p> <p>在 11.5 节中讲过异常日志的告警，并且会在 12.2 节中再次详细讲解告警，所以在本节不再做过多介绍，下面介绍日志的实时存储。</p> <h3 id="日志实时存储"><a href="#日志实时存储" class="header-anchor">#</a> 日志实时存储</h3> <p>因为日志最终是要在界面上展示的，在页面上不仅要查看实时的日志，可能也想去查看历史的应用日志，所以得有个地方去将这些历史的日志存储下来，然后页面上通过接口去查询日志。至于为什么本节要将日志数据存储在
ElasticSearch 呢？其实建议读者也多从不同的层次去考虑原因，比如：</p> <ul><li>查询的复杂度：对于日志的展示、搜索、分析这些场景查询日志的条件有多复杂？不同的存储是否都能够满足这些查询条件？</li> <li>数据量：得看每天日志数据量，如果每天的数据量很大，存储是否能够支撑这么大数据量的实时写入？历史数据变多后搜索查询的性能会不会骤降？</li> <li>运维成本：团队是否有人熟悉该存储中间件？后期扩容维护等工作的复杂性如何？</li> <li>社区活跃度：该存储中间件社区是否活跃？是否有足够的资料去学习？</li></ul> <p>ElasticSearch 是一款非常强大的开源搜索及分析引擎，除了搜索，它还可以结合 Kibana、Logstash 和 Beats
等组件一起应用在大数据近实时分析领域。在国内，阿里巴巴、腾讯、百度、滴滴、字节跳动等诸多知名公司都在使用 Elasticsearch。</p> <p>在 3.9 节中讲过 Flink 的 Connector —— ElasticSearch，并且也通过一个样例讲解了如何将 Metrics 数据写入进
ElasticSearch，那么其实和现在将日志数据写入进 ElasticSearch
是一致的，两种情况的数据量都是很大，区别就是两个的结构不一样，可能需要对 Metrics 数据和日志数据索引设置不同的
template。所以这里就简单的提供下代码。</p> <p>​</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogSink2ES</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">sink2es</span><span class="token punctuation">(</span><span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LogEvent</span><span class="token punctuation">&gt;</span></span> logDataStream<span class="token punctuation">,</span> <span class="token class-name">ParameterTool</span> parameterTool<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">HttpHost</span><span class="token punctuation">&gt;</span></span> esAddresses <span class="token operator">=</span> <span class="token class-name">ESSinkUtil</span><span class="token punctuation">.</span><span class="token function">getEsAddresses</span><span class="token punctuation">(</span>parameterTool<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>ELASTICSEARCH_HOSTS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">int</span> bulkSize <span class="token operator">=</span> parameterTool<span class="token punctuation">.</span><span class="token function">getInt</span><span class="token punctuation">(</span>ELASTICSEARCH_BULK_FLUSH_MAX_ACTIONS<span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">int</span> sinkParallelism <span class="token operator">=</span> parameterTool<span class="token punctuation">.</span><span class="token function">getInt</span><span class="token punctuation">(</span>STREAM_SINK_PARALLELISM<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">ESSinkUtil</span><span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span>esAddresses<span class="token punctuation">,</span> bulkSize<span class="token punctuation">,</span> sinkParallelism<span class="token punctuation">,</span> logDataStream<span class="token punctuation">,</span>
                <span class="token punctuation">(</span><span class="token class-name">LogEvent</span> logEvent<span class="token punctuation">,</span> <span class="token class-name">RuntimeContext</span> runtimeContext<span class="token punctuation">,</span> <span class="token class-name">RequestIndexer</span> requestIndexer<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
                    requestIndexer<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Requests</span><span class="token punctuation">.</span><span class="token function">indexRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                            <span class="token punctuation">.</span><span class="token function">index</span><span class="token punctuation">(</span><span class="token string">&quot;zhisheng_log&quot;</span><span class="token punctuation">)</span>
                            <span class="token punctuation">.</span><span class="token function">type</span><span class="token punctuation">(</span>ZHISHENG<span class="token punctuation">)</span>
                            <span class="token punctuation">.</span><span class="token function">source</span><span class="token punctuation">(</span><span class="token class-name">GsonUtil</span><span class="token punctuation">.</span><span class="token function">toJSONBytes</span><span class="token punctuation">(</span>logEvent<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">XContentType</span><span class="token punctuation">.</span>JSON<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span><span class="token punctuation">,</span>
                parameterTool<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="日志实时展示"><a href="#日志实时展示" class="header-anchor">#</a> 日志实时展示</h3> <p>数据已经存储到 ElasticSearch 了，接下来就是日志的展示和分析了，因为 ElasticSearch 和 Kibana
搭配在一起就能够将日志的展示、分析、搜索功能完成，并且这套技术在很多公司也是比较流行的了，所以这里也是选型
Kibana，当然如果你们公司有人力，可以自己提供数据展示的接口和页面。</p> <p>要完成该日志的展示需要先安装好
Kibana，关于如何下载和安装本节不做过多介绍，读者可以自行去官网下载安装包并安装。因为所有的日志数据都已经提供了，那么使用 Kibana
做数据展示其实就是要稍加配置一下 Kibana 就行了。下图是启动好 Kibana 之后，打开 <code>http://localhost:5601</code> 页面的效果。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-133302.png" alt="images">
因为在日志写入进 ElasticSearch 的作业中配置的日志索引是 <code>zhisheng_log</code>，所以得在 Kibana 左侧的 Management
页面去配置一个日志索引，这里我们使用的是 <code>*log</code> 的模版，发现只找到一个 <code>zhisheng_log</code> 的索引，接下来就一直点下一步就好了。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-135027.png" alt="images">
配置好索引后的页面如下图所示。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-135315.png" alt="images">
这时我们要搜索日志的话，可以点击左侧的 Discover，就会出现日志了，另外还提供搜素框，支持搜索关键字，搜索结果中的关键字还会高亮。</p> <p><img src="https://static.lovedata.net/zs/2019-10-27-135500.png" alt="images"></p> <h3 id="小结与反思"><a href="#小结与反思" class="header-anchor">#</a> 小结与反思</h3> <p>本节讲解了一个生产环境中的大型案例 ——
日志的实时处理系统，从需求分析到架构设计，再到日志数据的采集、数据清洗、异常日志的实时告警、数据的存储和数据的可视化展示，通过这个大型案例让你了解到一个项目的全链路，让你对整个项目开发的生命周期有了一定的了解，同时笔者也希望你能从该案例中获得启发，然后将其部分思想应用在你们自己公司的场景中，让你在你们公司起到主干力量的作用。另外，你们公司有日志实时处理的系统吗？其架构又是怎么样的呢？对比本节的内容，你觉得你们的系统有什么地方需要完善和补充的地方呢？</p> <p>本节涉及的代码地址：https://github.com/zhisheng17/flink-learning/tree/master/flink-
learning-monitor/flink-learning-monitor-log</p> <p>pattern 文件链接：https://github.com/thekrakken/java-
grok/blob/master/src/main/resources/patterns/patterns</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/pengshuangbao/databook/edit/master/docs/bigdata/flink/Flink实战与性能优化/基于Flink的海量日志实时处理系统的实践.md" target="_blank" rel="noopener noreferrer">Edit this page on GitHub</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">2023/4/14 16:56:47</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/bigdata/flink/Flink实战与性能优化/如何实时将应用Error日志告警？.html" class="prev">
        如何实时将应用Error日志告警？
      </a></span> <span class="next"><a href="/bigdata/flink/Flink实战与性能优化/基于Flink的百亿数据去重实践.html">
        基于Flink的百亿数据去重实践
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.0f56a723.js" defer></script><script src="/assets/js/4.a8ef5668.js" defer></script><script src="/assets/js/57.b0cbba56.js" defer></script><script src="/assets/js/11.0473ae06.js" defer></script>
  </body>
</html>
