(window.webpackJsonp=window.webpackJsonp||[]).push([[99],{560:function(t,a,s){"use strict";s.r(a);var e=s(14),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"hive底层执行逻辑深度剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hive底层执行逻辑深度剖析"}},[t._v("#")]),t._v(" Hive底层执行逻辑深度剖析")]),t._v(" "),s("p"),s("div",{staticClass:"table-of-contents"},[s("ul",[s("li",[s("a",{attrs:{href:"#hive定义"}},[t._v("Hive定义")])]),s("li",[s("a",{attrs:{href:"#架构"}},[t._v("架构")])]),s("li",[s("a",{attrs:{href:"#语法支持"}},[t._v("语法支持")]),s("ul",[s("li",[s("a",{attrs:{href:"#mapreduce-执行原理"}},[t._v("MapReduce 执行原理")]),s("ul",[s("li",[s("a",{attrs:{href:"#join实现"}},[t._v("Join实现")])]),s("li",[s("a",{attrs:{href:"#group-by"}},[t._v("Group  by")])]),s("li",[s("a",{attrs:{href:"#distinct"}},[t._v("Distinct")])])])])])]),s("li",[s("a",{attrs:{href:"#怎么转换成mr的"}},[t._v("怎么转换成MR的")]),s("ul",[s("li",[s("a",{attrs:{href:"#原理"}},[t._v("原理")])])])])])]),s("p"),t._v(" "),s("p",[t._v("FaceBook的工程师早期在使用开源Hadoop进行海量数据分析的时候，发现直接编写MapReduce比较低效,遂研发了一个Hadoop的SQL客户端来管理存储在Hadoop中的结构化数据，从而提高开发效率,而且也降低了入\n门大数据开发和分析的门]槛。\n未来开发的趋势:")]),t._v(" "),s("ol",[s("li",[t._v("Web UI平台")]),t._v(" "),s("li",[t._v("SQL开发/拖拽开发")]),t._v(" "),s("li",[t._v("流式计算处理引擎")])]),t._v(" "),s("p",[t._v("一句话总结就是:将来的大数据处理，都是平台化的管理方式,底层运行的是高效的流式计算引擎,用户的不是直接编写流式计算弓|擎的应用代码，而是SQL语句。")]),t._v(" "),s("h2",{attrs:{id:"hive定义"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hive定义"}},[t._v("#")]),t._v(" Hive定义")]),t._v(" "),s("p",[t._v("Hive依赖于HDFS存储数据I Hive将HQL转换成MapReduce执行，所以说Hive是基于Hadoop的一个数据仓 库工具，实质就是一款基于HDFS的MapReduce计算框架， 对存储在HDFS中的数据进行分析和管理。")]),t._v(" "),s("ol",[s("li",[t._v("Hive由Facebook实现并开源")]),t._v(" "),s("li",[t._v("Hive是基于Hadoop的一个数据仓库工具")]),t._v(" "),s("li",[t._v("Hive存储的数据其实底层存储在HDFS上")]),t._v(" "),s("li",[t._v("Hive将HDFS上的结构化的数据映射为一张数据库表，类似于exce1或者msyq1的表")]),t._v(" "),s("li",[t._v("Hive提供HQL (Hive SQL) 查询功能")]),t._v(" "),s("li",[t._v("Hive的本质是将SQL语句转换为MapReduce任务运行，使不熟悉MapReduce的用户很方便地利用HQL处理和计算HDFS\n上的结构化的数据，适用于离线的批量数据计算")]),t._v(" "),s("li",[t._v("Hive 使用户可以极大简化分布式计算程序的编写，而将精力集中于业务逻辑")])]),t._v(" "),s("h2",{attrs:{id:"架构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#架构"}},[t._v("#")]),t._v(" 架构")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-7a17e2e96617198524ca6ad9430b40bc.png",alt:"image"}})]),t._v(" "),s("h2",{attrs:{id:"语法支持"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#语法支持"}},[t._v("#")]),t._v(" 语法支持")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hive SQL的编译过程 - 美团技术团队"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("支持的语法: .")]),t._v(" "),s("div",{staticClass:"language-text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("1. select * from db. table1\n2. select count(distinct uid) from db. tab7e1\n3. 支持select、union a11. join (1eft、right、fu11 join)、1ike、where、having、 各种聚合函数、支持\njson解析\n4. UDF (User Defined Function) / UDAF/UDTF\n5. 不支持update和delete\n6. hive虽然支持in/exists (老版本是不支持的)，但是hive推荐使用semi join的方式来代替实现， 而且效率更\n高。\n7. 支持case .. when\n")])])]),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" groupby "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("having")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" Timit "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),s("p",[t._v("不支持的语法:")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.")]),t._v(" 支持等值链接，不支持非等值链接\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" 可以\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" 不可以\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v(" 支持"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v("多条件过滤，不支持"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("or")]),t._v("多条件过滤\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" 可以\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("，b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("or")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" 不可以\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.")]),t._v(" 不支持"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),t._v("和"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("delete")]),t._v("\n")])])]),s("h3",{attrs:{id:"mapreduce-执行原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-执行原理"}},[t._v("#")]),t._v(" MapReduce 执行原理")]),t._v(" "),s("p",[t._v("mapreduce的执行原理! ! !\n我和李老师，和玄姐三个斗地主，但是呢，只要一幅旧扑克牌。 54张")]),t._v(" "),s("ol",[s("li",[t._v("我手速很快，一个人快速的数一下\n作死的提升机器的性能。单 机处理思维")]),t._v(" "),s("li",[t._v("我随便把这旧牌分成三堆，我， 李老师，玄姐。一人数一堆。效率有所提升。 缺少汇总阶段\n我，李老师，玄姐===> 54分布式处理思维\n分布式处理思维\n必然分成两个阶段:\n1. 一个复杂的任务拆分成多个小任务这些小任务可以并行执行I\n2. 这多个小任务的计算结果需要进行汇总执行汇总")])]),t._v(" "),s("h4",{attrs:{id:"join实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#join实现"}},[t._v("#")]),t._v(" Join实现")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" o"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" orderid "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" O "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),t._v(" u "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" o"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uid "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" uid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-364dbe212d8b2f15566cd51c7f9a9bca.png",alt:"image"}})]),t._v(" "),s("h4",{attrs:{id:"group-by"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#group-by"}},[t._v("#")]),t._v(" Group  by")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" rank"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" isonline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" city "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" rank "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" isonline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-4970c718bf9cf81a8f777e179c55366a.png",alt:"image"}})]),t._v(" "),s("h4",{attrs:{id:"distinct"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#distinct"}},[t._v("#")]),t._v(" Distinct")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" dealid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("distinct")]),t._v(" uid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" num "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" dealid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-77d7d2c3fd82db09c29574b8499c499f.png",alt:"image"}})]),t._v(" "),s("h2",{attrs:{id:"怎么转换成mr的"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#怎么转换成mr的"}},[t._v("#")]),t._v(" 怎么转换成MR的")]),t._v(" "),s("p",[t._v("了解了MapReduce实现SQL基本操作之后,我们来看看Hive是如何将SQL转化为MapReduce任务的,整个编译过\n程分为六个阶段:")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Antlr 定义SQL的语法规则，完成SQL词法， 语法解析，将SQL转化为抽象语法树AST Tree 树上的每个节点就是一个 AST Node")])]),t._v(" "),s("li",[s("p",[t._v("遍历AST Tree，抽象出查询的基本组成单元QueryBlock 子查询")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-5a4602d62baee65b5af790a45d3a9f07.png",alt:"image"}})])]),t._v(" "),s("li",[s("p",[t._v("遍历QueryB1ock，翻译为执行操作树operatorTree")])]),t._v(" "),s("li",[s("p",[t._v("逻辑层优化器进行operatorTree变换，合并不必要的Reducesi nkoperator,减少shuff1e数据量")])]),t._v(" "),s("li",[s("p",[t._v("遍历operatorTree，翻译为MapReduce任务")])]),t._v(" "),s("li",[s("p",[t._v("物理层优化器进行MapReduce任务的变换，生成最终的执行计划")])])]),t._v(" "),s("h3",{attrs:{id:"原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#原理"}},[t._v("#")]),t._v(" 原理")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-28-a31deb261cb35ec910455f0dfd794a4d.png",alt:"image"}})])])}),[],!1,null,null,null);a.default=n.exports}}]);