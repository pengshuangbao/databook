(window.webpackJsonp=window.webpackJsonp||[]).push([[107],{565:function(a,t,s){"use strict";s.r(t);var r=s(14),v=Object(r.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"大数据集群资源评估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#大数据集群资源评估"}},[a._v("#")]),a._v(" 大数据集群资源评估")]),a._v(" "),s("p"),s("div",{staticClass:"table-of-contents"},[s("ul",[s("li",[s("a",{attrs:{href:"#集群资源评估"}},[a._v("集群资源评估")]),s("ul",[s("li",[s("a",{attrs:{href:"#某二手电商需要构建一个kafka集群-该集群的目标就是每天要hold住10亿请"}},[a._v("某二手电商需要构建一个Kafka集群，该集群的目标就是每天要hold住10亿请")]),s("ul",[s("li",[s("a",{attrs:{href:"#qps估算"}},[a._v("QPS估算")])]),s("li",[s("a",{attrs:{href:"#存储估算"}},[a._v("存储估算")])]),s("li",[s("a",{attrs:{href:"#qps角度"}},[a._v("QPS角度")])]),s("li",[s("a",{attrs:{href:"#磁盘的数量"}},[a._v("磁盘的数量")])]),s("li",[s("a",{attrs:{href:"#磁盘的类型"}},[a._v("磁盘的类型")])]),s("li",[s("a",{attrs:{href:"#内存角度"}},[a._v("内存角度")])]),s("li",[s("a",{attrs:{href:"#cpu角度"}},[a._v("CPU角度")])]),s("li",[s("a",{attrs:{href:"#网卡角度"}},[a._v("网卡角度")])]),s("li",[s("a",{attrs:{href:"#集群资源规划"}},[a._v("集群资源规划")])])])])])])])]),s("p"),a._v(" "),s("h2",{attrs:{id:"集群资源评估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群资源评估"}},[a._v("#")]),a._v(" 集群资源评估")]),a._v(" "),s("h3",{attrs:{id:"某二手电商需要构建一个kafka集群-该集群的目标就是每天要hold住10亿请"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#某二手电商需要构建一个kafka集群-该集群的目标就是每天要hold住10亿请"}},[a._v("#")]),a._v(" 某二手电商需要构建一个Kafka集群，该集群的目标就是每天要hold住10亿请")]),a._v(" "),s("h4",{attrs:{id:"qps估算"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#qps估算"}},[a._v("#")]),a._v(" QPS估算")]),a._v(" "),s("p",[a._v("每天集群需要承载10亿数据请求，一天24小时,对于电商网站，晚上12点到凌晨8点这8个小时几乎没多少数据。\n使用二八法则估计，也就是80%的数据(8亿)会在其余1 6个小时涌入，而且8亿的80%的数据(6.4亿) 会在\n这1 6个小时的20%时间(3小时)涌入。\nQPS计算公式=640000000+(3"),s("em",[a._v("60")]),a._v("60)=6万，故高峰期Kafka集群需要要抗住每秒6万的并发。")]),a._v(" "),s("h4",{attrs:{id:"存储估算"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#存储估算"}},[a._v("#")]),a._v(" 存储估算")]),a._v(" "),s("p",[a._v("每天10亿数据，每个请求50kb,也就是46T的数据。如果保存2副本，46"),s("em",[a._v("2=92T, 保留最近3天的数据。故需要92")]),a._v("3=276T\n注:一条消息50kb是我们公司的情况，这个值是偏大的，很多公司的- -个Kafka的请求里数据达不到50k这么大。")]),a._v(" "),s("h4",{attrs:{id:"qps角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#qps角度"}},[a._v("#")]),a._v(" QPS角度")]),a._v(" "),s("p",[a._v("如果资源充足，让高峰期QPS控制在集群能承载的总QPS的30%左右，故目前kafka集群能承载的总QPS为\n20万~30万才是安全的,根据经验- -台物理机能支持4万QPS是没问题的，所以从QPS的角度讲，需要物理\n机5-7台。")]),a._v(" "),s("h4",{attrs:{id:"磁盘的数量"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#磁盘的数量"}},[a._v("#")]),a._v(" 磁盘的数量")]),a._v(" "),s("p",[a._v("需要多少个磁盘?")]),a._v(" "),s("p",[a._v("5台物理机，需要存储276T的数据，每台存储60T的数据，- -般的配置是11块盘，一个盘7T就搞定。")]),a._v(" "),s("h4",{attrs:{id:"磁盘的类型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#磁盘的类型"}},[a._v("#")]),a._v(" 磁盘的类型")]),a._v(" "),s("p",[a._v("是需要SSD固态硬盘，还是普通SAS机械硬盘?\nSSD就是固态硬盘，比机械硬盘要快，SSD的快主要是快在磁盘随机读写\nKafka是顺序写的，"),s("strong",[a._v("机械硬盘顺序写的性能机会跟内存读写的性能")]),a._v("是差不多的，所以对于Kafka集群使用机\n械硬盘就可以了。")]),a._v(" "),s("h4",{attrs:{id:"内存角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#内存角度"}},[a._v("#")]),a._v(" 内存角度")]),a._v(" "),s("p",[a._v("Kafka自身的jvm是用不了过多堆内存，因为kafka设计就是规避掉用jvm对象来保存数据,避免频繁fullgc导\n致的问题，所以- -般kafka自身的jvm堆内存，分配个6G左右就够了,剩下的内存全部留给os cache。")]),a._v(" "),s("p",[a._v("每台服务器需要多少内存")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-25-d3728527d610145950dccaa7e67cdf5f.png",alt:"image"}})]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-25-5156e846257e20c55eccb9471f955765.png",alt:"image"}})]),a._v(" "),s("p",[a._v("经过梳理，公司集群大概有100个topic,这100个topic的partition的数据在os chache里效果是最好的。100个topic, 一个topic有5\n个partition。那么总共会有500个partition。每个partition的Log文件大小是1G,我们有2个副本，也就是说要把1 00个topic的partition数据都驻留在内存里需要1000G的内存。我们现在有5台服务器，所以平均下来每天服务器需要200G的内存，但是其实partition的数据我们没必要所有的都要驻留在内存里面，只需要25%的数据在内存就行，200G * 0.25 = 50G就可以了。所以- -共需要56G的内存，故我们可以挑选64G内存的服务器也行，当然如果是128G内存那就更好。")]),a._v(" "),s("h4",{attrs:{id:"cpu角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cpu角度"}},[a._v("#")]),a._v(" CPU角度")]),a._v(" "),s("p",[a._v("CPU規刻，主要是看Kafka迸程里会有多少个銭程J銭程主要是依托多核CPU来抗行的，如果銭程特別多，但是CPU核很少，就会尋致CPU奐載很高，会尋致整体工作銭程抗行的效率不太高。")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-25-e2ef10cf27ac29af7a67b2ba60d7f22e.png",alt:"image"}})]),a._v(" "),s("ol",[s("li",[a._v("Accept线程")]),a._v(" "),s("li",[a._v("默认的3个Process线程( -般会设置程9个)")]),a._v(" "),s("li",[a._v("默认的8RequestHandle线程(可以设置成32个)")]),a._v(" "),s("li",[a._v("清理日志的线程")]),a._v(" "),s("li",[a._v("感知Controller状态的线程")]),a._v(" "),s("li",[a._v("副本同步的线程\n"),s("strong",[a._v("估算下来Kafka内部有100多个线程")])])]),a._v(" "),s("p",[a._v("4个cpu core, -般来说几十个线程，在高峰期CPU几乎都快打满了。8个cpu core,也就能够比较宽裕的支撑几十个线程繁忙的工作。所以Kafka的服务器一般是建议16核， 基本上可以hold住一两百线程的工作。当然如果可以给到32 cpu core那就最好不过了!")]),a._v(" "),s("h4",{attrs:{id:"网卡角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#网卡角度"}},[a._v("#")]),a._v(" 网卡角度")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static.lovedata.net/21-05-26-97be4886401a3ada6606c49d0a9ed0d6.png",alt:"image"}})]),a._v(" "),s("ol",[s("li",[a._v("接受请求")]),a._v(" "),s("li",[a._v("副本同步")])]),a._v(" "),s("p",[a._v("每秒两台broker机器之间大概会传输多大的数据量?高峰期每秒大概会涌入6万个请求，约每台处理10000个请求，每个请求50kb，故每秒约进来488M数据，我们还有副本同步数据，故高峰期的时候需要488M * 2 = 976M/s的网络带宽，所以在高峰期的时候，使用千兆带宽，网络还是非常有压力的。")]),a._v(" "),s("h4",{attrs:{id:"集群资源规划"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群资源规划"}},[a._v("#")]),a._v(" 集群资源规划")]),a._v(" "),s("p",[a._v("1 0亿请求，6w/s的吞吐量，276T的数据，5台物理机\n硬盘: 11 (SAS) * 7T，7200转\n内存: 64GB/1 28GB, JVM分配6G,剩余的给os cache\nCPU: 16核/32核\n网络:千兆网卡，万兆更好")])])}),[],!1,null,null,null);t.default=v.exports}}]);